{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0bc7bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set(font_scale=2.2)\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split, ShuffleSplit\n",
    "from sklearn.metrics import f1_score\n",
    "import itertools\n",
    "# import lightgbm as lgb  # http://rette.iruis.net/2019/11/%EB%A7%A5%EC%97%90%EC%84%9C-%EB%8F%99%EC%A0%81-%EB%9D%BC%EC%9D%B4%EB%B8%8C%EB%9F%AC%EB%A6%AC-%EC%B0%B8%EC%A1%B0%EB%AC%B8%EC%A0%9C-reason-image-not-found/\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "# import shap   # featuretools 설치하니까 error뜸\n",
    "from tqdm import tqdm\n",
    "import featuretools as ft\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bd72e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.12.0\n",
      "  latest version: 23.1.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /Users/gimhayun/opt/anaconda3/envs/yourenvname\n",
      "\n",
      "  added / updated specs:\n",
      "    - xgboost\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    _py-xgboost-mutex-2.0      |            cpu_0           8 KB  conda-forge\n",
      "    ca-certificates-2022.12.7  |       h033912b_0         142 KB  conda-forge\n",
      "    certifi-2022.12.7          |     pyhd8ed1ab_0         147 KB  conda-forge\n",
      "    joblib-1.2.0               |     pyhd8ed1ab_0         205 KB  conda-forge\n",
      "    libblas-3.9.0              |16_osx64_openblas          13 KB  conda-forge\n",
      "    libcblas-3.9.0             |16_osx64_openblas          13 KB  conda-forge\n",
      "    libcxx-15.0.7              |       h71dddab_0         1.1 MB  conda-forge\n",
      "    libgfortran-5.0.0          |11_3_0_h97931a8_31         156 KB  conda-forge\n",
      "    libgfortran5-12.2.0        |      he409387_31         1.5 MB  conda-forge\n",
      "    liblapack-3.9.0            |16_osx64_openblas          13 KB  conda-forge\n",
      "    libopenblas-0.3.21         |openmp_h429af6e_3         9.6 MB  conda-forge\n",
      "    libxgboost-1.7.1           |   cpu_h0c1cf5f_0         2.7 MB  conda-forge\n",
      "    llvm-openmp-15.0.7         |       h61d9ccf_0         287 KB  conda-forge\n",
      "    numpy-1.24.2               |   py38h5a2dcdf_0         6.0 MB  conda-forge\n",
      "    openssl-1.1.1t             |       hfd90126_0         1.7 MB  conda-forge\n",
      "    py-xgboost-1.7.1           |cpu_py38he866dac_0         197 KB  conda-forge\n",
      "    python_abi-3.8             |           2_cp38           4 KB  conda-forge\n",
      "    scikit-learn-1.2.2         |   py38h573ff9c_0         6.6 MB  conda-forge\n",
      "    scipy-1.9.3                |   py38hfb8b963_2        22.9 MB  conda-forge\n",
      "    threadpoolctl-3.1.0        |     pyh8a188c0_0          18 KB  conda-forge\n",
      "    xgboost-1.7.1              |cpu_py38ha5ba132_0          13 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        53.3 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  _py-xgboost-mutex  conda-forge/osx-64::_py-xgboost-mutex-2.0-cpu_0\n",
      "  joblib             conda-forge/noarch::joblib-1.2.0-pyhd8ed1ab_0\n",
      "  libblas            conda-forge/osx-64::libblas-3.9.0-16_osx64_openblas\n",
      "  libcblas           conda-forge/osx-64::libcblas-3.9.0-16_osx64_openblas\n",
      "  libgfortran        conda-forge/osx-64::libgfortran-5.0.0-11_3_0_h97931a8_31\n",
      "  libgfortran5       conda-forge/osx-64::libgfortran5-12.2.0-he409387_31\n",
      "  liblapack          conda-forge/osx-64::liblapack-3.9.0-16_osx64_openblas\n",
      "  libopenblas        conda-forge/osx-64::libopenblas-0.3.21-openmp_h429af6e_3\n",
      "  libxgboost         conda-forge/osx-64::libxgboost-1.7.1-cpu_h0c1cf5f_0\n",
      "  llvm-openmp        conda-forge/osx-64::llvm-openmp-15.0.7-h61d9ccf_0\n",
      "  numpy              conda-forge/osx-64::numpy-1.24.2-py38h5a2dcdf_0\n",
      "  py-xgboost         conda-forge/osx-64::py-xgboost-1.7.1-cpu_py38he866dac_0\n",
      "  python_abi         conda-forge/osx-64::python_abi-3.8-2_cp38\n",
      "  scikit-learn       conda-forge/osx-64::scikit-learn-1.2.2-py38h573ff9c_0\n",
      "  scipy              conda-forge/osx-64::scipy-1.9.3-py38hfb8b963_2\n",
      "  threadpoolctl      conda-forge/noarch::threadpoolctl-3.1.0-pyh8a188c0_0\n",
      "  xgboost            conda-forge/osx-64::xgboost-1.7.1-cpu_py38ha5ba132_0\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates    pkgs/main::ca-certificates-2022.4.26-~ --> conda-forge::ca-certificates-2022.12.7-h033912b_0\n",
      "  certifi            pkgs/main/osx-64::certifi-2022.5.18.1~ --> conda-forge/noarch::certifi-2022.12.7-pyhd8ed1ab_0\n",
      "  libcxx                pkgs/main::libcxx-12.0.0-h2f01273_0 --> conda-forge::libcxx-15.0.7-h71dddab_0\n",
      "  openssl              pkgs/main::openssl-1.1.1o-hca72f7f_0 --> conda-forge::openssl-1.1.1t-hfd90126_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "certifi-2022.12.7    | 147 KB    | ##################################### | 100% \n",
      "libcblas-3.9.0       | 13 KB     | ##################################### | 100% \n",
      "libxgboost-1.7.1     | 2.7 MB    | ##################################### | 100% \n",
      "_py-xgboost-mutex-2. | 8 KB      | ##################################### | 100% \n",
      "numpy-1.24.2         | 6.0 MB    | ##################################### | 100% \n",
      "threadpoolctl-3.1.0  | 18 KB     | ##################################### | 100% \n",
      "xgboost-1.7.1        | 13 KB     | ##################################### | 100% \n",
      "libopenblas-0.3.21   | 9.6 MB    | ##################################### | 100% \n",
      "python_abi-3.8       | 4 KB      | ##################################### | 100% \n",
      "scikit-learn-1.2.2   | 6.6 MB    | ##################################### | 100% \n",
      "ca-certificates-2022 | 142 KB    | ##################################### | 100% \n",
      "libblas-3.9.0        | 13 KB     | ##################################### | 100% \n",
      "libgfortran5-12.2.0  | 1.5 MB    | ##################################### | 100% \n",
      "scipy-1.9.3          | 22.9 MB   | ##################################### | 100% \n",
      "libcxx-15.0.7        | 1.1 MB    | ##################################### | 100% \n",
      "openssl-1.1.1t       | 1.7 MB    | ##################################### | 100% \n",
      "llvm-openmp-15.0.7   | 287 KB    | ##################################### | 100% \n",
      "liblapack-3.9.0      | 13 KB     | ##################################### | 100% \n",
      "py-xgboost-1.7.1     | 197 KB    | ##################################### | 100% \n",
      "libgfortran-5.0.0    | 156 KB    | ##################################### | 100% \n",
      "joblib-1.2.0         | 205 KB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install -c conda-forge xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7f12e3",
   "metadata": {},
   "source": [
    "# 1. Check datasets\n",
    "\n",
    "## 1.1 Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b9a92ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../input/train.csv')\n",
    "df_test = pd.read_csv('../input/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b722a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train shape: (9557, 143)    df_test shape:  (23856, 142)\n"
     ]
    }
   ],
   "source": [
    "print('df_train shape:', df_train.shape, '  ', 'df_test shape: ', df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85416e8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>v2a1</th>\n",
       "      <th>hacdor</th>\n",
       "      <th>rooms</th>\n",
       "      <th>hacapo</th>\n",
       "      <th>v14a</th>\n",
       "      <th>refrig</th>\n",
       "      <th>v18q</th>\n",
       "      <th>v18q1</th>\n",
       "      <th>r4h1</th>\n",
       "      <th>...</th>\n",
       "      <th>SQBescolari</th>\n",
       "      <th>SQBage</th>\n",
       "      <th>SQBhogar_total</th>\n",
       "      <th>SQBedjefe</th>\n",
       "      <th>SQBhogar_nin</th>\n",
       "      <th>SQBovercrowding</th>\n",
       "      <th>SQBdependency</th>\n",
       "      <th>SQBmeaned</th>\n",
       "      <th>agesq</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_279628684</td>\n",
       "      <td>190000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>1849</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1849</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_f29eb3ddd</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>144</td>\n",
       "      <td>4489</td>\n",
       "      <td>1</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>64.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>4489</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_68de51c94</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>121</td>\n",
       "      <td>8464</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>64.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>8464</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_d671db89c</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>81</td>\n",
       "      <td>289</td>\n",
       "      <td>16</td>\n",
       "      <td>121</td>\n",
       "      <td>4</td>\n",
       "      <td>1.777778</td>\n",
       "      <td>1.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>289</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_d56d6f5f5</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>121</td>\n",
       "      <td>1369</td>\n",
       "      <td>16</td>\n",
       "      <td>121</td>\n",
       "      <td>4</td>\n",
       "      <td>1.777778</td>\n",
       "      <td>1.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>1369</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 143 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Id      v2a1  hacdor  rooms  hacapo  v14a  refrig  v18q  v18q1  \\\n",
       "0  ID_279628684  190000.0       0      3       0     1       1     0    NaN   \n",
       "1  ID_f29eb3ddd  135000.0       0      4       0     1       1     1    1.0   \n",
       "2  ID_68de51c94       NaN       0      8       0     1       1     0    NaN   \n",
       "3  ID_d671db89c  180000.0       0      5       0     1       1     1    1.0   \n",
       "4  ID_d56d6f5f5  180000.0       0      5       0     1       1     1    1.0   \n",
       "\n",
       "   r4h1  ...  SQBescolari  SQBage  SQBhogar_total  SQBedjefe  SQBhogar_nin  \\\n",
       "0     0  ...          100    1849               1        100             0   \n",
       "1     0  ...          144    4489               1        144             0   \n",
       "2     0  ...          121    8464               1          0             0   \n",
       "3     0  ...           81     289              16        121             4   \n",
       "4     0  ...          121    1369              16        121             4   \n",
       "\n",
       "   SQBovercrowding  SQBdependency  SQBmeaned  agesq  Target  \n",
       "0         1.000000            0.0      100.0   1849       4  \n",
       "1         1.000000           64.0      144.0   4489       4  \n",
       "2         0.250000           64.0      121.0   8464       4  \n",
       "3         1.777778            1.0      121.0    289       4  \n",
       "4         1.777778            1.0      121.0   1369       4  \n",
       "\n",
       "[5 rows x 143 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecb5fb01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>v2a1</th>\n",
       "      <th>hacdor</th>\n",
       "      <th>rooms</th>\n",
       "      <th>hacapo</th>\n",
       "      <th>v14a</th>\n",
       "      <th>refrig</th>\n",
       "      <th>v18q</th>\n",
       "      <th>v18q1</th>\n",
       "      <th>r4h1</th>\n",
       "      <th>...</th>\n",
       "      <th>age</th>\n",
       "      <th>SQBescolari</th>\n",
       "      <th>SQBage</th>\n",
       "      <th>SQBhogar_total</th>\n",
       "      <th>SQBedjefe</th>\n",
       "      <th>SQBhogar_nin</th>\n",
       "      <th>SQBovercrowding</th>\n",
       "      <th>SQBdependency</th>\n",
       "      <th>SQBmeaned</th>\n",
       "      <th>agesq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_2f6873615</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>272.25</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_1c78846d2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>41</td>\n",
       "      <td>256</td>\n",
       "      <td>1681</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>272.25</td>\n",
       "      <td>1681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_e5442cf6a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>41</td>\n",
       "      <td>289</td>\n",
       "      <td>1681</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>272.25</td>\n",
       "      <td>1681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_a8db26a79</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>59</td>\n",
       "      <td>256</td>\n",
       "      <td>3481</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>256.00</td>\n",
       "      <td>3481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_a62966799</td>\n",
       "      <td>175000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>121</td>\n",
       "      <td>324</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.25</td>\n",
       "      <td>64.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 142 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Id      v2a1  hacdor  rooms  hacapo  v14a  refrig  v18q  v18q1  \\\n",
       "0  ID_2f6873615       NaN       0      5       0     1       1     0    NaN   \n",
       "1  ID_1c78846d2       NaN       0      5       0     1       1     0    NaN   \n",
       "2  ID_e5442cf6a       NaN       0      5       0     1       1     0    NaN   \n",
       "3  ID_a8db26a79       NaN       0     14       0     1       1     1    1.0   \n",
       "4  ID_a62966799  175000.0       0      4       0     1       1     1    1.0   \n",
       "\n",
       "   r4h1  ...  age  SQBescolari  SQBage  SQBhogar_total  SQBedjefe  \\\n",
       "0     1  ...    4            0      16               9          0   \n",
       "1     1  ...   41          256    1681               9          0   \n",
       "2     1  ...   41          289    1681               9          0   \n",
       "3     0  ...   59          256    3481               1        256   \n",
       "4     0  ...   18          121     324               1          0   \n",
       "\n",
       "   SQBhogar_nin  SQBovercrowding  SQBdependency  SQBmeaned  agesq  \n",
       "0             1             2.25           0.25     272.25     16  \n",
       "1             1             2.25           0.25     272.25   1681  \n",
       "2             1             2.25           0.25     272.25   1681  \n",
       "3             0             1.00           0.00     256.00   3481  \n",
       "4             1             0.25          64.00        NaN    324  \n",
       "\n",
       "[5 rows x 142 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2223709",
   "metadata": {},
   "source": [
    "## 1.2 Make description df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04e78b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "description = [\n",
    "(\"v2a1\",\" Monthly rent payment\"),\n",
    "(\"hacdor\",\" =1 Overcrowding by bedrooms\"),\n",
    "(\"rooms\",\"  number of all rooms in the house\"),\n",
    "(\"hacapo\",\" =1 Overcrowding by rooms\"),\n",
    "(\"v14a\",\" =1 has toilet in the household\"),\n",
    "(\"refrig\",\" =1 if the household has refrigerator\"),\n",
    "(\"v18q\",\" owns a tablet\"),\n",
    "(\"v18q1\",\" number of tablets household owns\"),\n",
    "(\"r4h1\",\" Males younger than 12 years of age\"),\n",
    "(\"r4h2\",\" Males 12 years of age and older\"),\n",
    "(\"r4h3\",\" Total males in the household\"),\n",
    "(\"r4m1\",\" Females younger than 12 years of age\"),\n",
    "(\"r4m2\",\" Females 12 years of age and older\"),\n",
    "(\"r4m3\",\" Total females in the household\"),\n",
    "(\"r4t1\",\" persons younger than 12 years of age\"),\n",
    "(\"r4t2\",\" persons 12 years of age and older\"),\n",
    "(\"r4t3\",\" Total persons in the household\"),\n",
    "(\"tamhog\",\" size of the household\"),\n",
    "(\"tamviv\",\" number of persons living in the household\"),\n",
    "(\"escolari\",\" years of schooling\"),\n",
    "(\"rez_esc\",\" Years behind in school\"),\n",
    "(\"hhsize\",\" household size\"),\n",
    "(\"paredblolad\",\" =1 if predominant material on the outside wall is block or brick\"),\n",
    "(\"paredzocalo\",\" =1 if predominant material on the outside wall is socket (wood, zinc or absbesto\"),\n",
    "(\"paredpreb\",\" =1 if predominant material on the outside wall is prefabricated or cement\"),\n",
    "(\"pareddes\",\" =1 if predominant material on the outside wall is waste material\"),\n",
    "(\"paredmad\",\" =1 if predominant material on the outside wall is wood\"),\n",
    "(\"paredzinc\",\" =1 if predominant material on the outside wall is zink\"),\n",
    "(\"paredfibras\",\" =1 if predominant material on the outside wall is natural fibers\"),\n",
    "(\"paredother\",\" =1 if predominant material on the outside wall is other\"),\n",
    "(\"pisomoscer\",\" =1 if predominant material on the floor is mosaic ceramic   terrazo\"),\n",
    "(\"pisocemento\",\" =1 if predominant material on the floor is cement\"),\n",
    "(\"pisoother\",\" =1 if predominant material on the floor is other\"),\n",
    "(\"pisonatur\",\" =1 if predominant material on the floor is  natural material\"),\n",
    "(\"pisonotiene\",\" =1 if no floor at the household\"),\n",
    "(\"pisomadera\",\" =1 if predominant material on the floor is wood\"),\n",
    "(\"techozinc\",\" =1 if predominant material on the roof is metal foil or zink\"),\n",
    "(\"techoentrepiso\",\" =1 if predominant material on the roof is fiber cement,   mezzanine \"),\n",
    "(\"techocane\",\" =1 if predominant material on the roof is natural fibers\"),\n",
    "(\"techootro\",\" =1 if predominant material on the roof is other\"),\n",
    "(\"cielorazo\",\" =1 if the house has ceiling\"),\n",
    "(\"abastaguadentro\",\" =1 if water provision inside the dwelling\"),\n",
    "(\"abastaguafuera\",\" =1 if water provision outside the dwelling\"),\n",
    "(\"abastaguano\",\" =1 if no water provision\"),\n",
    "(\"public\",\" =1 electricity from CNFL,  ICE, ESPH/JASEC\"),\n",
    "(\"planpri\",\" =1 electricity from private plant\"),\n",
    "(\"noelec\",\" =1 no electricity in the dwelling\"),\n",
    "(\"coopele\",\" =1 electricity from cooperative\"),\n",
    "(\"sanitario1\",\" =1 no toilet in the dwelling\"),\n",
    "(\"sanitario2\",\" =1 toilet connected to sewer or cesspool\"),\n",
    "(\"sanitario3\",\" =1 toilet connected to  septic tank\"),\n",
    "(\"sanitario5\",\" =1 toilet connected to black hole or letrine\"),\n",
    "(\"sanitario6\",\" =1 toilet connected to other system\"),\n",
    "(\"energcocinar1\",\" =1 no main source of energy used for cooking (no kitchen)\"),\n",
    "(\"energcocinar2\",\" =1 main source of energy used for cooking electricity\"),\n",
    "(\"energcocinar3\",\" =1 main source of energy used for cooking gas\"),\n",
    "(\"energcocinar4\",\" =1 main source of energy used for cooking wood charcoal\"),\n",
    "(\"elimbasu1\",\" =1 if rubbish disposal mainly by tanker truck\"),\n",
    "(\"elimbasu2\",\" =1 if rubbish disposal mainly by botan hollow or buried\"),\n",
    "(\"elimbasu3\",\" =1 if rubbish disposal mainly by burning\"),\n",
    "(\"elimbasu4\",\" =1 if rubbish disposal mainly by throwing in an unoccupied space\"),\n",
    "(\"elimbasu5\",\" =1 if rubbish disposal mainly by throwing in river,   creek or sea\"),\n",
    "(\"elimbasu6\",\" =1 if rubbish disposal mainly other\"),\n",
    "(\"epared1\",\" =1 if walls are bad\"),\n",
    "(\"epared2\",\" =1 if walls are regular\"),\n",
    "(\"epared3\",\" =1 if walls are good\"),\n",
    "(\"etecho1\",\" =1 if roof are bad\"),\n",
    "(\"etecho2\",\" =1 if roof are regular\"),\n",
    "(\"etecho3\",\" =1 if roof are good\"),\n",
    "(\"eviv1\",\" =1 if floor are bad\"),\n",
    "(\"eviv2\",\" =1 if floor are regular\"),\n",
    "(\"eviv3\",\" =1 if floor are good\"),\n",
    "(\"dis\",\" =1 if disable person\"),\n",
    "(\"male\",\" =1 if male\"),\n",
    "(\"female\",\" =1 if female\"),\n",
    "(\"estadocivil1\",\" =1 if less than 10 years old\"),\n",
    "(\"estadocivil2\",\" =1 if free or coupled uunion\"),\n",
    "(\"estadocivil3\",\" =1 if married\"),\n",
    "(\"estadocivil4\",\" =1 if divorced\"),\n",
    "(\"estadocivil5\",\" =1 if separated\"),\n",
    "(\"estadocivil6\",\" =1 if widow/er\"),\n",
    "(\"estadocivil7\",\" =1 if single\"),\n",
    "(\"parentesco1\",\" =1 if household head\"),\n",
    "(\"parentesco2\",\" =1 if spouse/partner\"),\n",
    "(\"parentesco3\",\" =1 if son/doughter\"),\n",
    "(\"parentesco4\",\" =1 if stepson/doughter\"),\n",
    "(\"parentesco5\",\" =1 if son/doughter in law\"),\n",
    "(\"parentesco6\",\" =1 if grandson/doughter\"),\n",
    "(\"parentesco7\",\" =1 if mother/father\"),\n",
    "(\"parentesco8\",\" =1 if father/mother in law\"),\n",
    "(\"parentesco9\",\" =1 if brother/sister\"),\n",
    "(\"parentesco10\",\" =1 if brother/sister in law\"),\n",
    "(\"parentesco11\",\" =1 if other family member\"),\n",
    "(\"parentesco12\",\" =1 if other non family member\"),\n",
    "(\"idhogar\",\" Household level identifier\"),\n",
    "(\"hogar_nin\",\" Number of children 0 to 19 in household\"),\n",
    "(\"hogar_adul\",\" Number of adults in household\"),\n",
    "(\"hogar_mayor\",\" # of individuals 65+ in the household\"),\n",
    "(\"hogar_total\",\" # of total individuals in the household\"),\n",
    "(\"dependency\",\" Dependency rate\"),\n",
    "(\"edjefe\",\" years of education of male head of household\"),\n",
    "(\"edjefa\",\" years of education of female head of household\"),\n",
    "(\"meaneduc\",\"average years of education for adults (18+)\"),\n",
    "(\"instlevel1\",\" =1 no level of education\"),\n",
    "(\"instlevel2\",\" =1 incomplete primary\"),\n",
    "(\"instlevel3\",\" =1 complete primary\"),\n",
    "(\"instlevel4\",\" =1 incomplete academic secondary level\"),\n",
    "(\"instlevel5\",\" =1 complete academic secondary level\"),\n",
    "(\"instlevel6\",\" =1 incomplete technical secondary level\"),\n",
    "(\"instlevel7\",\" =1 complete technical secondary level\"),\n",
    "(\"instlevel8\",\" =1 undergraduate and higher education\"),\n",
    "(\"instlevel9\",\" =1 postgraduate higher education\"),\n",
    "(\"bedrooms\",\" number of bedrooms\"),\n",
    "(\"overcrowding\",\" # persons per room\"),\n",
    "(\"tipovivi1\",\" =1 own and fully paid house\"),\n",
    "(\"tipovivi2\",\" =1 own,   paying in installments\"),\n",
    "(\"tipovivi3\",\" =1 rented\"),\n",
    "(\"tipovivi4\",\" =1 precarious\"),\n",
    "(\"tipovivi5\",\" =1 other(assigned\"),\n",
    "(\"computer\",\" =1 if the household has notebook or desktop computer,   borrowed)\"),\n",
    "(\"television\",\" =1 if the household has TV\"),\n",
    "(\"mobilephone\",\" =1 if mobile phone\"),\n",
    "(\"qmobilephone\",\" # of mobile phones\"),\n",
    "(\"lugar1\",\" =1 region Central\"),\n",
    "(\"lugar2\",\" =1 region Chorotega\"),\n",
    "(\"lugar3\",\" =1 region PacÃƒÂ­fico central\"),\n",
    "(\"lugar4\",\" =1 region Brunca\"),\n",
    "(\"lugar5\",\" =1 region Huetar AtlÃƒÂ¡ntica\"),\n",
    "(\"lugar6\",\" =1 region Huetar Norte\"),\n",
    "(\"area1\",\" =1 zona urbana\"),\n",
    "(\"area2\",\" =2 zona rural\"),\n",
    "(\"age\",\" Age in years\"),\n",
    "(\"SQBescolari\",\" escolari squared\"),\n",
    "(\"SQBage\",\" age squared\"),\n",
    "(\"SQBhogar_total\",\" hogar_total squared\"),\n",
    "(\"SQBedjefe\",\" edjefe squared\"),\n",
    "(\"SQBhogar_nin\",\" hogar_nin squared\"),\n",
    "(\"SQBovercrowding\",\" overcrowding squared\"),\n",
    "(\"SQBdependency\",\" dependency squared\"),\n",
    "(\"SQBmeaned\",\" meaned squared\"),\n",
    "(\"agesq\",\" Age squared\"),]\n",
    "\n",
    "description = pd.DataFrame(description, columns=['varname', 'description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86f8a2f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>varname</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>v2a1</td>\n",
       "      <td>Monthly rent payment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hacdor</td>\n",
       "      <td>=1 Overcrowding by bedrooms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rooms</td>\n",
       "      <td>number of all rooms in the house</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hacapo</td>\n",
       "      <td>=1 Overcrowding by rooms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>v14a</td>\n",
       "      <td>=1 has toilet in the household</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>SQBhogar_nin</td>\n",
       "      <td>hogar_nin squared</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>SQBovercrowding</td>\n",
       "      <td>overcrowding squared</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>SQBdependency</td>\n",
       "      <td>dependency squared</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>SQBmeaned</td>\n",
       "      <td>meaned squared</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>agesq</td>\n",
       "      <td>Age squared</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>141 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             varname                         description\n",
       "0               v2a1                Monthly rent payment\n",
       "1             hacdor         =1 Overcrowding by bedrooms\n",
       "2              rooms    number of all rooms in the house\n",
       "3             hacapo            =1 Overcrowding by rooms\n",
       "4               v14a      =1 has toilet in the household\n",
       "..               ...                                 ...\n",
       "136     SQBhogar_nin                   hogar_nin squared\n",
       "137  SQBovercrowding                overcrowding squared\n",
       "138    SQBdependency                  dependency squared\n",
       "139        SQBmeaned                      meaned squared\n",
       "140            agesq                         Age squared\n",
       "\n",
       "[141 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e657e2",
   "metadata": {},
   "source": [
    "## 1.3 Check null data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00264381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rez_esc</th>\n",
       "      <td>7928</td>\n",
       "      <td>82.954902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v18q1</th>\n",
       "      <td>7342</td>\n",
       "      <td>76.823271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v2a1</th>\n",
       "      <td>6860</td>\n",
       "      <td>71.779847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SQBmeaned</th>\n",
       "      <td>5</td>\n",
       "      <td>0.052318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meaneduc</th>\n",
       "      <td>5</td>\n",
       "      <td>0.052318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hogar_adul</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parentesco10</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parentesco11</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parentesco12</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idhogar</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hogar_nin</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dependency</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hogar_mayor</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hogar_total</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>edjefe</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>edjefa</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instlevel1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instlevel2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parentesco9</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Total    Percent\n",
       "rez_esc        7928  82.954902\n",
       "v18q1          7342  76.823271\n",
       "v2a1           6860  71.779847\n",
       "SQBmeaned         5   0.052318\n",
       "meaneduc          5   0.052318\n",
       "Id                0   0.000000\n",
       "hogar_adul        0   0.000000\n",
       "parentesco10      0   0.000000\n",
       "parentesco11      0   0.000000\n",
       "parentesco12      0   0.000000\n",
       "idhogar           0   0.000000\n",
       "hogar_nin         0   0.000000\n",
       "dependency        0   0.000000\n",
       "hogar_mayor       0   0.000000\n",
       "hogar_total       0   0.000000\n",
       "edjefe            0   0.000000\n",
       "edjefa            0   0.000000\n",
       "instlevel1        0   0.000000\n",
       "instlevel2        0   0.000000\n",
       "parentesco9       0   0.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = df_train.isnull().sum().sort_values(ascending=False)\n",
    "percent = 100 * (df_train.isnull().sum() / df_train.isnull().count()).sort_values(ascending=False)\n",
    "missing_df = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "\n",
    "missing_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312c11f4",
   "metadata": {},
   "source": [
    "## 1.4 Fill missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886bb344",
   "metadata": {},
   "source": [
    "- Below cell is from this kernel. https://www.kaggle.com/skooch/lgbm-w-random-split-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15fc3f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if education is \"yes\" and person is head of household, fill with escolari\n",
    "df_train.loc[(df_train['edjefa'] == \"yes\") & (df_train['parentesco1'] == 1), \"edjefa\"] = df_train.loc[(df_train['edjefa'] == \"yes\") & (df_train['parentesco1'] == 1), \"escolari\"]\n",
    "df_train.loc[(df_train['edjefe'] == \"yes\") & (df_train['parentesco1'] == 1), \"edjefe\"] = df_train.loc[(df_train['edjefe'] == \"yes\") & (df_train['parentesco1'] == 1), \"escolari\"]\n",
    "\n",
    "df_test.loc[(df_test['edjefa'] == \"yes\") & (df_test['parentesco1'] == 1), \"edjefa\"] = df_test.loc[(df_test['edjefa'] == \"yes\") & (df_test['parentesco1'] == 1), \"escolari\"]\n",
    "df_test.loc[(df_test['edjefe'] == \"yes\") & (df_test['parentesco1'] == 1), \"edjefe\"] = df_test.loc[(df_test['edjefe'] == \"yes\") & (df_test['parentesco1'] == 1), \"escolari\"]\n",
    "\n",
    "# this field is supposed to be interaction between gender and escolari, but it isn't clear what \"yes\" means, let's fill it with 4\n",
    "df_train.loc[df_train['edjefa'] == \"yes\", \"edjefa\"] = 4\n",
    "df_train.loc[df_train['edjefe'] == \"yes\", \"edjefe\"] = 4\n",
    "\n",
    "df_test.loc[df_test['edjefa'] == \"yes\", \"edjefa\"] = 4\n",
    "df_test.loc[df_test['edjefe'] == \"yes\", \"edjefe\"] = 4\n",
    "\n",
    "# create feature with max education of either head of household\n",
    "df_train['edjef'] = np.max(df_train[['edjefa','edjefe']], axis=1)\n",
    "df_test['edjef'] = np.max(df_test[['edjefa','edjefe']], axis=1)\n",
    "\n",
    "# fix some inconsistencies in the data - some rows indicate both that the household does and does not have a toilet, \n",
    "# if there is no water we'll assume they do not\n",
    "df_train.loc[(df_train.v14a ==  1) & (df_train.sanitario1 ==  1) & (df_train.abastaguano == 0), \"v14a\"] = 0\n",
    "df_train.loc[(df_train.v14a ==  1) & (df_train.sanitario1 ==  1) & (df_train.abastaguano == 0), \"sanitario1\"] = 0\n",
    "\n",
    "df_test.loc[(df_test.v14a ==  1) & (df_test.sanitario1 ==  1) & (df_test.abastaguano == 0), \"v14a\"] = 0\n",
    "df_test.loc[(df_test.v14a ==  1) & (df_test.sanitario1 ==  1) & (df_test.abastaguano == 0), \"sanitario1\"] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47a4ca8",
   "metadata": {},
   "source": [
    "### rez_esz, SQBmeaned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ead20e",
   "metadata": {},
   "source": [
    "- rez_esc : Years behind in school -> filled with 0\n",
    "- SQBmeaned : square of the mean years of education of adults (>=18) in the household agesq, Age squared -> same with rez_esc -> filled with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f50a88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['rez_esc'].fillna(0, inplace=True)\n",
    "df_test['rez_esc'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "392acb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['SQBmeaned'].fillna(0, inplace=True)\n",
    "df_test['SQBmeaned'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8196844",
   "metadata": {},
   "source": [
    "### meaneduc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988cb60e",
   "metadata": {},
   "source": [
    "- meaneduc: average years of education for adults (18+) -> filled with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "935a967d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['meaneduc'].fillna(0, inplace=True)\n",
    "df_test['meaneduc'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a41924",
   "metadata": {},
   "source": [
    "### v18q1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eca198b",
   "metadata": {},
   "source": [
    "- v18q1: number of tablets household owns -> if v18q(Do you own a tablet?) == 1, there are some values. If not, only NaN values in v18q1. See below 3 cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64e87d87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7342\n",
       "1    2215\n",
       "Name: v18q, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['v18q'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14a884d",
   "metadata": {},
   "source": [
    "- v18q1: number of tablets household owns -> if v18q == 1, there are some values. If not, only NaN values there. See below two cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24e388b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    1586\n",
       "2.0     444\n",
       "3.0     129\n",
       "4.0      37\n",
       "5.0      13\n",
       "6.0       6\n",
       "Name: v18q1, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.loc[df_train['v18q'] == 1, 'v18q1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "884953a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: v18q1, dtype: int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.loc[df_train['v18q'] == 0, 'v18q1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86fb2cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['v18q1'].fillna(0, inplace=True)\n",
    "df_test['v18q1'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0493279f",
   "metadata": {},
   "source": [
    "- v2a1: number of tablets household owns -> if tipovivi3(rented?) == 1, there are some values. If not, there are also some values.\n",
    "- NaN value could be replaced by 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c581a7a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7821\n",
       "1    1736\n",
       "Name: tipovivi3, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['tipovivi3'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb73fdd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.kdeplot(df_train.loc[df_train['tipovivi3'] == 1, 'v2a1'], label='Monthly rent payment of household(rented=1)')\n",
    "sns.kdeplot(df_train.loc[df_train['tipovivi3'] == 0, 'v2a1'], label='Monthly rent payment of household(rented=0)')\n",
    "plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "688311d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['v2a1'].fillna(0, inplace=True)\n",
    "df_test['v2a1'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a3538dff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>edjef</th>\n",
       "      <td>9557</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v2a1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parentesco10</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parentesco11</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parentesco12</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idhogar</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hogar_nin</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hogar_adul</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hogar_mayor</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hogar_total</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dependency</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>edjefe</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>edjefa</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meaneduc</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instlevel1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instlevel2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instlevel3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parentesco9</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parentesco8</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parentesco7</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Total  Percent\n",
       "edjef          9557    100.0\n",
       "v2a1              0      0.0\n",
       "parentesco10      0      0.0\n",
       "parentesco11      0      0.0\n",
       "parentesco12      0      0.0\n",
       "idhogar           0      0.0\n",
       "hogar_nin         0      0.0\n",
       "hogar_adul        0      0.0\n",
       "hogar_mayor       0      0.0\n",
       "hogar_total       0      0.0\n",
       "dependency        0      0.0\n",
       "edjefe            0      0.0\n",
       "edjefa            0      0.0\n",
       "meaneduc          0      0.0\n",
       "instlevel1        0      0.0\n",
       "instlevel2        0      0.0\n",
       "instlevel3        0      0.0\n",
       "parentesco9       0      0.0\n",
       "parentesco8       0      0.0\n",
       "parentesco7       0      0.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = df_train.isnull().sum().sort_values(ascending=False)\n",
    "percent = 100 * (df_train.isnull().sum() / df_train.isnull().count()).sort_values(ascending=False)\n",
    "missing_df = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "\n",
    "missing_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "99ae43fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>edjef</th>\n",
       "      <td>23856</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hogar_mayor</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parentesco10</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parentesco11</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parentesco12</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idhogar</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hogar_nin</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hogar_adul</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hogar_total</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parentesco8</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dependency</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>edjefe</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>edjefa</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meaneduc</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instlevel1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instlevel2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parentesco9</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parentesco7</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instlevel4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>estadocivil5</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Total  Percent\n",
       "edjef         23856    100.0\n",
       "hogar_mayor       0      0.0\n",
       "parentesco10      0      0.0\n",
       "parentesco11      0      0.0\n",
       "parentesco12      0      0.0\n",
       "idhogar           0      0.0\n",
       "hogar_nin         0      0.0\n",
       "hogar_adul        0      0.0\n",
       "hogar_total       0      0.0\n",
       "parentesco8       0      0.0\n",
       "dependency        0      0.0\n",
       "edjefe            0      0.0\n",
       "edjefa            0      0.0\n",
       "meaneduc          0      0.0\n",
       "instlevel1        0      0.0\n",
       "instlevel2        0      0.0\n",
       "parentesco9       0      0.0\n",
       "parentesco7       0      0.0\n",
       "instlevel4        0      0.0\n",
       "estadocivil5      0      0.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = df_test.isnull().sum().sort_values(ascending=False)\n",
    "percent = 100 * (df_test.isnull().sum() / df_test.isnull().count()).sort_values(ascending=False)\n",
    "missing_df = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "\n",
    "missing_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a9a03f",
   "metadata": {},
   "source": [
    "For now, there are no NaN values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b494df",
   "metadata": {},
   "source": [
    "# 2. Feature engineering\n",
    "\n",
    "## 2.1 Object features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a1f8bad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_object = [col for col in df_train.columns if df_train[col].dtype == 'object']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec9a9dab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Id', 'idhogar', 'dependency', 'edjefe', 'edjefa']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33b8461",
   "metadata": {},
   "source": [
    "### dependecy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "32c68dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some dependencies are Na, fill those with the square root of the square\n",
    "df_train['dependency'] = np.sqrt(df_train['SQBdependency'])\n",
    "df_test['dependency'] = np.sqrt(df_test['SQBdependency'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "07852682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train['dependency'] = df_train['dependency'].replace({np.inf: 0})\n",
    "# df_test['dependency'] = df_test['dependency'].replace({np.inf: 0})\n",
    "\n",
    "# def replace_dependency(x):\n",
    "#     if x == 'yes':\n",
    "#         return 10\n",
    "#     elif x == 'no':\n",
    "#         return 0\n",
    "#     else:\n",
    "#         return x\n",
    "\n",
    "# df_train['dependency'] = df_train['dependency'].apply(replace_dependency).astype(float)\n",
    "# df_test['dependency'] = df_test['dependency'].apply(replace_dependency).astype(float)\n",
    "\n",
    "# - As you can see, setting yes -> 10 and no -> 0 is good choice.\n",
    "# - At first, fill inf value with 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c1cdd7",
   "metadata": {},
   "source": [
    "### edjefe\n",
    "\n",
    "- edjefe, years of education of male head of household, based on the interaction of escolari (years of education), head of household and gender, yes=1 and no=0\n",
    "- replace yes -> 1 and no -> 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bef9e5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_edjefe(x):\n",
    "    if x == 'yes':\n",
    "        return 1\n",
    "    elif x == 'no':\n",
    "        return 0\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "df_train['edjefe'] = df_train['edjefe'].apply(replace_edjefe).astype(float)\n",
    "df_test['edjefe'] = df_test['edjefe'].apply(replace_edjefe).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea35af8f",
   "metadata": {},
   "source": [
    "### edjefa\n",
    "\n",
    "- edjefa, years of education of female head of household, based on the interaction of escolari (years of education), head of household and gender, yes=1 and no=0\n",
    "- replace yes -> 1 and no -> 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4a6702f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_edjefa(x):\n",
    "    if x == 'yes':\n",
    "        return 1\n",
    "    elif x == 'no':\n",
    "        return 0\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "df_train['edjefa'] = df_train['edjefa'].apply(replace_edjefa).astype(float)\n",
    "df_test['edjefa'] = df_test['edjefa'].apply(replace_edjefa).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f3545acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create feature with max education of either head of household\n",
    "df_train['edjef'] = np.max(df_train[['edjefa','edjefe']], axis=1)\n",
    "df_test['edjef'] = np.max(df_test[['edjefa','edjefe']], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51693075",
   "metadata": {},
   "source": [
    "### roof and electricity\n",
    "\n",
    "- I refered to https://www.kaggle.com/mineshjethva/exploratory-data-analysis-lightgbm. Thanks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f29d6b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['roof_waste_material'] = np.nan\n",
    "df_test['roof_waste_material'] = np.nan\n",
    "df_train['electricity_other'] = np.nan\n",
    "df_test['electricity_other'] = np.nan\n",
    "\n",
    "def fill_roof_exception(x):\n",
    "    if (x['techozinc'] == 0) and (x['techoentrepiso'] == 0) and (x['techocane'] == 0) and (x['techootro'] == 0):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def fill_no_electricity(x):\n",
    "    if (x['public'] == 0) and (x['planpri'] == 0) and (x['noelec'] == 0) and (x['coopele'] == 0):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "df_train['roof_waste_material'] = df_train.apply(lambda x : fill_roof_exception(x),axis=1)\n",
    "df_test['roof_waste_material'] = df_test.apply(lambda x : fill_roof_exception(x),axis=1)\n",
    "df_train['electricity_other'] = df_train.apply(lambda x : fill_no_electricity(x),axis=1)\n",
    "df_test['electricity_other'] = df_test.apply(lambda x : fill_no_electricity(x),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b35c766",
   "metadata": {},
   "source": [
    "## 2.2 Extract cat features\n",
    "\n",
    "- According to data scription, there are many binary category features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "537d209f",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_cat_features = [col for col in df_train.columns if df_train[col].value_counts().shape[0] == 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb969a8",
   "metadata": {},
   "source": [
    "## 2.3 Make new features using continuous feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7021effc",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_features = [col for col in df_train.columns if col not in binary_cat_features]\n",
    "continuous_features = [col for col in continuous_features if col not in features_object]\n",
    "continuous_features = [col for col in continuous_features if col not in ['Id', 'Target', 'idhogar']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9deaebea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 37 continuous features\n",
      "v2a1: [' Monthly rent payment']\n",
      "rooms: ['  number of all rooms in the house']\n",
      "v18q1: [' number of tablets household owns']\n",
      "r4h1: [' Males younger than 12 years of age']\n",
      "r4h2: [' Males 12 years of age and older']\n",
      "r4h3: [' Total males in the household']\n",
      "r4m1: [' Females younger than 12 years of age']\n",
      "r4m2: [' Females 12 years of age and older']\n",
      "r4m3: [' Total females in the household']\n",
      "r4t1: [' persons younger than 12 years of age']\n",
      "r4t2: [' persons 12 years of age and older']\n",
      "r4t3: [' Total persons in the household']\n",
      "tamhog: [' size of the household']\n",
      "tamviv: [' number of persons living in the household']\n",
      "escolari: [' years of schooling']\n",
      "rez_esc: [' Years behind in school']\n",
      "hhsize: [' household size']\n",
      "elimbasu5: [' =1 if rubbish disposal mainly by throwing in river,   creek or sea']\n",
      "hogar_nin: [' Number of children 0 to 19 in household']\n",
      "hogar_adul: [' Number of adults in household']\n",
      "hogar_mayor: [' # of individuals 65+ in the household']\n",
      "hogar_total: [' # of total individuals in the household']\n",
      "meaneduc: ['average years of education for adults (18+)']\n",
      "bedrooms: [' number of bedrooms']\n",
      "overcrowding: [' # persons per room']\n",
      "qmobilephone: [' # of mobile phones']\n",
      "age: [' Age in years']\n",
      "SQBescolari: [' escolari squared']\n",
      "SQBage: [' age squared']\n",
      "SQBhogar_total: [' hogar_total squared']\n",
      "SQBedjefe: [' edjefe squared']\n",
      "SQBhogar_nin: [' hogar_nin squared']\n",
      "SQBovercrowding: [' overcrowding squared']\n",
      "SQBdependency: [' dependency squared']\n",
      "SQBmeaned: [' meaned squared']\n",
      "agesq: [' Age squared']\n",
      "edjef: []\n"
     ]
    }
   ],
   "source": [
    "print('There are {} continuous features'.format(len(continuous_features)))\n",
    "for col in continuous_features:\n",
    "    print('{}: {}'.format(col, description.loc[description['varname'] == col, 'description'].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c60cd88",
   "metadata": {},
   "source": [
    "- hhsize : household size\n",
    "- tamhog : size of the household\n",
    "\n",
    "What is different?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d68ad3",
   "metadata": {},
   "source": [
    "- As you can see, the meaning of two features are same but the exact number are different. Are they different?\n",
    "- I don't know. For now, I decided to drop one feature 'tamhog'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6dd1fb41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.0     2792\n",
       "11.0    1150\n",
       "9.0      723\n",
       "8.0      474\n",
       "15.0     473\n",
       "3.0      459\n",
       "0.0      435\n",
       "7.0      413\n",
       "4.0      400\n",
       "5.0      398\n",
       "14.0     328\n",
       "17.0     278\n",
       "2.0      278\n",
       "16.0     247\n",
       "10.0     207\n",
       "12.0     185\n",
       "13.0     155\n",
       "1.0       65\n",
       "21.0      48\n",
       "18.0      22\n",
       "19.0      18\n",
       "20.0       9\n",
       "Name: edjef, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['edjef'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ba6599f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop('tamhog', axis=1, inplace=True)\n",
    "df_test.drop('tamhog', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8b1c1c",
   "metadata": {},
   "source": [
    "### Squared features\n",
    "\n",
    "- There are many squared features. Actually, tree models like lightgbm don't need them. But at this kernel, I want to use lightgbm as feature filter model and set entity- embedding as classfier. So Let's keep them.\n",
    "\n",
    "\n",
    "### Family features\n",
    "\n",
    "- hogar_nin, hogar_adul, hogar_mayor, hogar_total, r4h1, r4h2, r4h3, r4m1, r4m2, r4m3, r4t1, r4t2, r4t3, tmbhog, tamvid, rez_esc, escolari\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Family size features (substract, ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "de1eecff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['adult'] = df_train['hogar_adul'] - df_train['hogar_mayor']\n",
    "df_train['dependency_count'] = df_train['hogar_nin'] + df_train['hogar_mayor']\n",
    "df_train['dependency'] = df_train['dependency_count'] / df_train['adult']\n",
    "df_train['child_percent'] = df_train['hogar_nin'] / df_train['hogar_total']\n",
    "df_train['elder_percent'] = df_train['hogar_mayor'] / df_train['hogar_total']\n",
    "df_train['adult_percent'] = df_train['hogar_adul'] / df_train['hogar_total']\n",
    "df_train['males_younger_12_years_percent'] = df_train['r4h1'] / df_train['hogar_total']\n",
    "df_train['males_older_12_years_percent'] = df_train['r4h2'] / df_train['hogar_total']\n",
    "df_train['males_percent'] = df_train['r4h3'] / df_train['hogar_total']\n",
    "df_train['females_younger_12_years_percent'] = df_train['r4m1'] / df_train['hogar_total']\n",
    "df_train['females_older_12_years_percent'] = df_train['r4m2'] / df_train['hogar_total']\n",
    "df_train['females_percent'] = df_train['r4m3'] / df_train['hogar_total']\n",
    "df_train['persons_younger_12_years_percent'] = df_train['r4t1'] / df_train['hogar_total']\n",
    "df_train['persons_older_12_years_percent'] = df_train['r4t2'] / df_train['hogar_total']\n",
    "df_train['persons_percent'] = df_train['r4t3'] / df_train['hogar_total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f579f6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['adult'] = df_test['hogar_adul'] - df_test['hogar_mayor']\n",
    "df_test['dependency_count'] = df_test['hogar_nin'] + df_test['hogar_mayor']\n",
    "df_test['dependency'] = df_test['dependency_count'] / df_test['adult']\n",
    "df_test['child_percent'] = df_test['hogar_nin'] / df_test['hogar_total']\n",
    "df_test['elder_percent'] = df_test['hogar_mayor'] / df_test['hogar_total']\n",
    "df_test['adult_percent'] = df_test['hogar_adul'] / df_test['hogar_total']\n",
    "df_test['males_younger_12_years_percent'] = df_test['r4h1'] / df_test['hogar_total']\n",
    "df_test['males_older_12_years_percent'] = df_test['r4h2'] / df_test['hogar_total']\n",
    "df_test['males_percent'] = df_test['r4h3'] / df_test['hogar_total']\n",
    "df_test['females_younger_12_years_percent'] = df_test['r4m1'] / df_test['hogar_total']\n",
    "df_test['females_older_12_years_percent'] = df_test['r4m2'] / df_test['hogar_total']\n",
    "df_test['females_percent'] = df_test['r4m3'] / df_test['hogar_total']\n",
    "df_test['persons_younger_12_years_percent'] = df_test['r4t1'] / df_test['hogar_total']\n",
    "df_test['persons_older_12_years_percent'] = df_test['r4t2'] / df_test['hogar_total']\n",
    "df_test['persons_percent'] = df_test['r4t3'] / df_test['hogar_total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "acfe9f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['males_younger_12_years_in_household_size'] = df_train['r4h1'] / df_train['hhsize']\n",
    "df_train['males_older_12_years_in_household_size'] = df_train['r4h2'] / df_train['hhsize']\n",
    "df_train['males_in_household_size'] = df_train['r4h3'] / df_train['hhsize']\n",
    "df_train['females_younger_12_years_in_household_size'] = df_train['r4m1'] / df_train['hhsize']\n",
    "df_train['females_older_12_years_in_household_size'] = df_train['r4m2'] / df_train['hhsize']\n",
    "df_train['females_in_household_size'] = df_train['r4m3'] / df_train['hogar_total']\n",
    "df_train['persons_younger_12_years_in_household_size'] = df_train['r4t1'] / df_train['hhsize']\n",
    "df_train['persons_older_12_years_in_household_size'] = df_train['r4t2'] / df_train['hhsize']\n",
    "df_train['persons_in_household_size'] = df_train['r4t3'] / df_train['hhsize']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e28807be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['males_younger_12_years_in_household_size'] = df_test['r4h1'] / df_test['hhsize']\n",
    "df_test['males_older_12_years_in_household_size'] = df_test['r4h2'] / df_test['hhsize']\n",
    "df_test['males_in_household_size'] = df_test['r4h3'] / df_test['hhsize']\n",
    "df_test['females_younger_12_years_in_household_size'] = df_test['r4m1'] / df_test['hhsize']\n",
    "df_test['females_older_12_years_in_household_size'] = df_test['r4m2'] / df_test['hhsize']\n",
    "df_test['females_in_household_size'] = df_test['r4m3'] / df_test['hogar_total']\n",
    "df_test['persons_younger_12_years_in_household_size'] = df_test['r4t1'] / df_test['hhsize']\n",
    "df_test['persons_older_12_years_in_household_size'] = df_test['r4t2'] / df_test['hhsize']\n",
    "df_test['persons_in_household_size'] = df_test['r4t3'] / df_test['hhsize']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c394d1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['overcrowding_room_and_bedroom'] = (df_train['hacdor'] + df_train['hacapo'])/2\n",
    "df_test['overcrowding_room_and_bedroom'] = (df_test['hacdor'] + df_test['hacapo'])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1104057a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['escolari_age'] = df_train['escolari']/df_train['age']\n",
    "df_test['escolari_age'] = df_test['escolari']/df_test['age']\n",
    "\n",
    "df_train['age_12_19'] = df_train['hogar_nin'] - df_train['r4t1']\n",
    "df_test['age_12_19'] = df_test['hogar_nin'] - df_test['r4t1']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a6ae26a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['phones-per-capita'] = df_train['qmobilephone'] / df_train['tamviv']\n",
    "df_train['tablets-per-capita'] = df_train['v18q1'] / df_train['tamviv']\n",
    "df_train['rooms-per-capita'] = df_train['rooms'] / df_train['tamviv']\n",
    "df_train['rent-per-capita'] = df_train['v2a1'] / df_train['tamviv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "efa0bcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['phones-per-capita'] = df_test['qmobilephone'] / df_test['tamviv']\n",
    "df_test['tablets-per-capita'] = df_test['v18q1'] / df_test['tamviv']\n",
    "df_test['rooms-per-capita'] = df_test['rooms'] / df_test['tamviv']\n",
    "df_test['rent-per-capita'] = df_test['v2a1'] / df_test['tamviv']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ac1cb8",
   "metadata": {},
   "source": [
    "- You can see that \"Total persons in the household\" != \"# of total individuals in the household\".\n",
    "- Somewhat weired. But for now I will keep it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fa28ba82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9509"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_train['hogar_total'] == df_train['r4t3']).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3e34b4",
   "metadata": {},
   "source": [
    "### Rent per family features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1576142",
   "metadata": {},
   "source": [
    "- I will reduce the number of features using shap, so let's generate many features!! Hope catch some fortune features :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4c566c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "family_size_features = ['adult', 'hogar_adul', 'hogar_mayor', 'hogar_nin', 'hogar_total', 'r4h1', \n",
    "                        'r4h2', 'r4h3', 'r4m1', 'r4m2', 'r4m3', 'r4t1', 'r4t2', 'r4t3', 'hhsize']\n",
    "new_feats = []\n",
    "for col in family_size_features:\n",
    "    new_col_name = 'new_{}_per_{}'.format('v2a1', col)\n",
    "    new_feats.append(new_col_name)\n",
    "    df_train[new_col_name] = df_train['v2a1'] / df_train[col]\n",
    "    df_test[new_col_name] = df_test['v2a1'] / df_test[col]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112e2b37",
   "metadata": {},
   "source": [
    "- Ratio feature can have infinite values. So Let them be filled with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b97fc294",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in new_feats:\n",
    "    df_train[col].replace([np.inf], np.nan, inplace=True)\n",
    "    df_train[col].fillna(0, inplace=True)\n",
    "    \n",
    "    df_test[col].replace([np.inf], np.nan, inplace=True)\n",
    "    df_test[col].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1aa453",
   "metadata": {},
   "source": [
    "### Room per family features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ffc02b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feats = []\n",
    "for col in family_size_features:\n",
    "    new_col_name = 'new_{}_per_{}'.format('rooms', col)\n",
    "    new_feats.append(new_col_name)\n",
    "    df_train[new_col_name] = df_train['rooms'] / df_train[col]\n",
    "    df_test[new_col_name] = df_test['rooms'] / df_test[col]\n",
    "\n",
    "for col in new_feats:\n",
    "    df_train[col].replace([np.inf], np.nan, inplace=True)\n",
    "    df_train[col].fillna(0, inplace=True)\n",
    "    \n",
    "    df_test[col].replace([np.inf], np.nan, inplace=True)\n",
    "    df_test[col].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7221a77",
   "metadata": {},
   "source": [
    "### BedRoom per family features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "280f1691",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feats = []\n",
    "for col in family_size_features:\n",
    "    new_col_name = 'new_{}_per_{}'.format('bedrooms', col)\n",
    "    new_feats.append(new_col_name)\n",
    "    df_train[new_col_name] = df_train['bedrooms'] / df_train[col]\n",
    "    df_test[new_col_name] = df_test['bedrooms'] / df_test[col]\n",
    "\n",
    "for col in new_feats:\n",
    "    df_train[col].replace([np.inf], np.nan, inplace=True)\n",
    "    df_train[col].fillna(0, inplace=True)\n",
    "    \n",
    "    df_test[col].replace([np.inf], np.nan, inplace=True)\n",
    "    df_test[col].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2e5fa043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9557, 220) (23856, 219)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape, df_test.shape) # To check the same number of features between train and test (target is there in train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447dcca0",
   "metadata": {},
   "source": [
    "### Tabulet per family features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "902a4b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feats = []\n",
    "for col in family_size_features:\n",
    "    new_col_name = 'new_{}_per_{}'.format('v18q1', col)\n",
    "    new_feats.append(new_col_name)\n",
    "    df_train[new_col_name] = df_train['v18q1'] / df_train[col]\n",
    "    df_test[new_col_name] = df_test['v18q1'] / df_test[col]\n",
    "\n",
    "for col in new_feats:\n",
    "    df_train[col].replace([np.inf], np.nan, inplace=True)\n",
    "    df_train[col].fillna(0, inplace=True)\n",
    "    \n",
    "    df_test[col].replace([np.inf], np.nan, inplace=True)\n",
    "    df_test[col].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e8680c",
   "metadata": {},
   "source": [
    "### phone per family features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d6cd85e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feats = []\n",
    "for col in family_size_features:\n",
    "    new_col_name = 'new_{}_per_{}'.format('qmobilephone', col)\n",
    "    new_feats.append(new_col_name)\n",
    "    df_train[new_col_name] = df_train['qmobilephone'] / df_train[col]\n",
    "    df_test[new_col_name] = df_test['qmobilephone'] / df_test[col]\n",
    "\n",
    "for col in new_feats:\n",
    "    df_train[col].replace([np.inf], np.nan, inplace=True)\n",
    "    df_train[col].fillna(0, inplace=True)\n",
    "    \n",
    "    df_test[col].replace([np.inf], np.nan, inplace=True)\n",
    "    df_test[col].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607b0eb2",
   "metadata": {},
   "source": [
    "### rez_esc(Years behind in school) per family features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "522ac577",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feats = []\n",
    "for col in family_size_features:\n",
    "    new_col_name = 'new_{}_per_{}'.format('rez_esc', col)\n",
    "    new_feats.append(new_col_name)\n",
    "    df_train[new_col_name] = df_train['rez_esc'] / df_train[col]\n",
    "    df_test[new_col_name] = df_test['rez_esc'] / df_test[col]\n",
    "\n",
    "for col in new_feats:\n",
    "    df_train[col].replace([np.inf], np.nan, inplace=True)\n",
    "    df_train[col].fillna(0, inplace=True)\n",
    "    \n",
    "    df_test[col].replace([np.inf], np.nan, inplace=True)\n",
    "    df_test[col].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1773b914",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['rez_esc_age'] = df_train['rez_esc'] / df_train['age']\n",
    "df_train['rez_esc_escolari'] = df_train['rez_esc'] / df_train['escolari']\n",
    "\n",
    "df_test['rez_esc_age'] = df_test['rez_esc'] / df_test['age']\n",
    "df_test['rez_esc_escolari'] = df_test['rez_esc'] / df_test['escolari']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a2e591",
   "metadata": {},
   "source": [
    "### Rich features\n",
    "\n",
    "- I think the more richer, the larger number of phones and tabulet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8a78a2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['tabulet_x_qmobilephone'] = df_train['v18q1'] * df_train['qmobilephone']\n",
    "df_test['tabulet_x_qmobilephone'] = df_test['v18q1'] * df_test['qmobilephone']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7599d4a",
   "metadata": {},
   "source": [
    "- wall, roof, floor may be key factor.\n",
    "- Let's multiply each of them. Becuase they are binary cat features, so mulitification of each features generates new categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6fb8990e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wall and roof\n",
    "for col1 in ['epared1', 'epared2', 'epared3']:\n",
    "    for col2 in ['etecho1', 'etecho2', 'etecho3']:\n",
    "        new_col_name = 'new_{}_x_{}'.format(col1, col2)\n",
    "        df_train[new_col_name] = df_train[col1] * df_train[col2]\n",
    "        df_test[new_col_name] = df_test[col1] * df_test[col2]\n",
    "        \n",
    "# wall and floor\n",
    "for col1 in ['epared1', 'epared2', 'epared3']:\n",
    "    for col2 in ['eviv1', 'eviv2', 'eviv3']:\n",
    "        new_col_name = 'new_{}_x_{}'.format(col1, col2)\n",
    "        df_train[new_col_name] = df_train[col1] * df_train[col2]\n",
    "        df_test[new_col_name] = df_test[col1] * df_test[col2]\n",
    "\n",
    "# roof and floor\n",
    "for col1 in ['etecho1', 'etecho2', 'etecho3']:\n",
    "    for col2 in ['eviv1', 'eviv2', 'eviv3']:\n",
    "        new_col_name = 'new_{}_x_{}'.format(col1, col2)\n",
    "        df_train[new_col_name] = df_train[col1] * df_train[col2]\n",
    "        df_test[new_col_name] = df_test[col1] * df_test[col2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57ce27e",
   "metadata": {},
   "source": [
    "- combination using three features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7965ce3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col1 in ['epared1', 'epared2', 'epared3']:\n",
    "    for col2 in ['etecho1', 'etecho2', 'etecho3']:\n",
    "        for col3 in ['eviv1', 'eviv2', 'eviv3']:\n",
    "            new_col_name = 'new_{}_x_{}_x_{}'.format(col1, col2, col3)\n",
    "            df_train[new_col_name] = df_train[col1] * df_train[col2] * df_train[col3]\n",
    "            df_test[new_col_name] = df_test[col1] * df_test[col2] * df_train[col3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3b4c750b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9557, 322) (23856, 321)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8912b7",
   "metadata": {},
   "source": [
    "- I want to mix electricity and energy features -> energy features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "dc3c5e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col1 in ['public', 'planpri', 'noelec', 'coopele']:\n",
    "    for col2 in ['energcocinar1', 'energcocinar2', 'energcocinar3', 'energcocinar4']:\n",
    "        new_col_name = 'new_{}_x_{}'.format(col1, col2)\n",
    "        df_train[new_col_name] = df_train[col1] * df_train[col2]\n",
    "        df_test[new_col_name] = df_test[col1] * df_test[col2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a5999b",
   "metadata": {},
   "source": [
    "- I want to mix toilet and rubbish disposal features -> other_infra features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ca948bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col1 in ['sanitario1', 'sanitario2', 'sanitario3', 'sanitario5', 'sanitario6']:\n",
    "    for col2 in ['elimbasu1', 'elimbasu2', 'elimbasu3', 'elimbasu4', 'elimbasu5', 'elimbasu6']:\n",
    "        new_col_name = 'new_{}_x_{}'.format(col1, col2)\n",
    "        df_train[new_col_name] = df_train[col1] * df_train[col2]\n",
    "        df_test[new_col_name] = df_test[col1] * df_test[col2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd641b3",
   "metadata": {},
   "source": [
    "- I want to mix toilet and water provision features -> water features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e6eba37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col1 in ['abastaguadentro', 'abastaguafuera', 'abastaguano']:\n",
    "    for col2 in ['sanitario1', 'sanitario2', 'sanitario3', 'sanitario5', 'sanitario6']:\n",
    "        new_col_name = 'new_{}_x_{}'.format(col1, col2)\n",
    "        df_train[new_col_name] = df_train[col1] * df_train[col2]\n",
    "        df_test[new_col_name] = df_test[col1] * df_test[col2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "66065879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9557, 383) (23856, 382)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0cffdf",
   "metadata": {},
   "source": [
    "- I want mix education and area features -> education_zone_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4ada214d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col1 in ['area1', 'area2']:\n",
    "    for col2 in ['instlevel1', 'instlevel2', 'instlevel3', 'instlevel4', 'instlevel5', 'instlevel6', 'instlevel7', 'instlevel8', 'instlevel9']:\n",
    "        new_col_name = 'new_{}_x_{}'.format(col1, col2)\n",
    "        df_train[new_col_name] = df_train[col1] * df_train[col2]\n",
    "        df_test[new_col_name] = df_test[col1] * df_test[col2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfd4230",
   "metadata": {},
   "source": [
    "- Mix region and education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "34ed0b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col1 in ['lugar1', 'lugar2', 'lugar3', 'lugar4', 'lugar5', 'lugar6']:\n",
    "    for col2 in ['instlevel1', 'instlevel2', 'instlevel3', 'instlevel4', 'instlevel5', 'instlevel6', 'instlevel7', 'instlevel8', 'instlevel9']:\n",
    "        new_col_name = 'new_{}_x_{}'.format(col1, col2)\n",
    "        df_train[new_col_name] = df_train[col1] * df_train[col2]\n",
    "        df_test[new_col_name] = df_test[col1] * df_test[col2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "03b8d2c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9557, 455) (23856, 454)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b10b41",
   "metadata": {},
   "source": [
    "- Multiply television / mobilephone / computer / tabulet / refrigerator -> electornics features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "52fbe586",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['electronics'] = df_train['computer'] * df_train['mobilephone'] * df_train['television'] * df_train['v18q'] * df_train['refrig']\n",
    "df_test['electronics'] = df_test['computer'] * df_test['mobilephone'] * df_test['television'] * df_test['v18q'] * df_test['refrig']\n",
    "\n",
    "df_train['no_appliances'] = df_train['refrig'] + df_train['computer'] + df_train['television'] + df_train['mobilephone']\n",
    "df_test['no_appliances'] = df_test['refrig'] + df_test['computer'] + df_test['television'] + df_test['mobilephone']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba17200",
   "metadata": {},
   "source": [
    "- Mix wall material of roof, floor, wall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2340468c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col1 in ['paredblolad', 'paredzocalo', 'paredpreb', 'pareddes', 'paredmad', 'paredzinc', 'paredfibras', 'paredother']:\n",
    "    for col2 in ['pisomoscer', 'pisocemento', 'pisoother', 'pisonatur', 'pisonotiene', 'pisomadera']:\n",
    "        new_col_name = 'new_{}_x_{}'.format(col1, col2)\n",
    "        df_train[new_col_name] = df_train[col1] * df_train[col2]\n",
    "        df_test[new_col_name] = df_test[col1] * df_test[col2]\n",
    "\n",
    "for col1 in ['pisomoscer', 'pisocemento', 'pisoother', 'pisonatur', 'pisonotiene', 'pisomadera']:\n",
    "    for col1 in ['techozinc', 'techoentrepiso', 'techocane', 'techootro']:\n",
    "        new_col_name = 'new_{}_x_{}'.format(col1, col2)\n",
    "        df_train[new_col_name] = df_train[col1] * df_train[col2]\n",
    "        df_test[new_col_name] = df_test[col1] * df_test[col2]\n",
    "        \n",
    "for col1 in ['paredblolad', 'paredzocalo', 'paredpreb', 'pareddes', 'paredmad', 'paredzinc', 'paredfibras', 'paredother']:\n",
    "    for col2 in ['techozinc', 'techoentrepiso', 'techocane', 'techootro']:\n",
    "        new_col_name = 'new_{}_x_{}'.format(col1, col2)\n",
    "        df_train[new_col_name] = df_train[col1] * df_train[col2]\n",
    "        df_test[new_col_name] = df_test[col1] * df_test[col2]        \n",
    "        \n",
    "for col1 in ['paredblolad', 'paredzocalo', 'paredpreb', 'pareddes', 'paredmad', 'paredzinc', 'paredfibras', 'paredother']:\n",
    "    for col2 in ['pisomoscer', 'pisocemento', 'pisoother', 'pisonatur', 'pisonotiene', 'pisomadera']:\n",
    "        for col3 in ['techozinc', 'techoentrepiso', 'techocane', 'techootro']:\n",
    "            new_col_name = 'new_{}_x_{}_x_{}'.format(col1, col2, col3)\n",
    "            df_train[new_col_name] = df_train[col1] * df_train[col2] * df_train[col3]\n",
    "            df_test[new_col_name] = df_test[col1] * df_test[col2] * df_train[col3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5dda2cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9557, 733) (23856, 732)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf417cad",
   "metadata": {},
   "source": [
    "- Wow! without any aggreation features, we hvae 446 features for now. Actually mixing the materials of walls make thousands of features. I don't want to do that because of computational costs!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9b7975",
   "metadata": {},
   "source": [
    "### Remove feature with only one value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "63f63b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elimbasu5\n",
      "new_planpri_x_energcocinar1\n",
      "new_planpri_x_energcocinar2\n",
      "new_planpri_x_energcocinar3\n",
      "new_planpri_x_energcocinar4\n",
      "new_noelec_x_energcocinar2\n",
      "new_sanitario1_x_elimbasu4\n",
      "new_sanitario1_x_elimbasu5\n",
      "new_sanitario1_x_elimbasu6\n",
      "new_sanitario2_x_elimbasu4\n",
      "new_sanitario2_x_elimbasu5\n",
      "new_sanitario2_x_elimbasu6\n",
      "new_sanitario3_x_elimbasu5\n",
      "new_sanitario5_x_elimbasu4\n",
      "new_sanitario5_x_elimbasu5\n",
      "new_sanitario5_x_elimbasu6\n",
      "new_sanitario6_x_elimbasu2\n",
      "new_sanitario6_x_elimbasu4\n",
      "new_sanitario6_x_elimbasu5\n",
      "new_sanitario6_x_elimbasu6\n",
      "new_abastaguafuera_x_sanitario6\n",
      "new_abastaguano_x_sanitario2\n",
      "new_abastaguano_x_sanitario6\n",
      "new_paredblolad_x_pisonatur\n",
      "new_paredblolad_x_pisonotiene\n",
      "new_paredzocalo_x_pisoother\n",
      "new_paredzocalo_x_pisonatur\n",
      "new_paredpreb_x_pisonatur\n",
      "new_pareddes_x_pisoother\n",
      "new_pareddes_x_pisonatur\n",
      "new_paredmad_x_pisoother\n",
      "new_paredmad_x_pisonatur\n",
      "new_paredzinc_x_pisoother\n",
      "new_paredzinc_x_pisonatur\n",
      "new_paredfibras_x_pisoother\n",
      "new_paredfibras_x_pisonatur\n",
      "new_paredfibras_x_pisonotiene\n",
      "new_paredfibras_x_pisomadera\n",
      "new_paredother_x_pisoother\n",
      "new_paredother_x_pisonatur\n",
      "new_paredother_x_pisonotiene\n",
      "new_paredother_x_pisomadera\n",
      "new_techocane_x_pisomadera\n",
      "new_techootro_x_pisomadera\n",
      "new_paredzocalo_x_techoentrepiso\n",
      "new_paredzocalo_x_techocane\n",
      "new_paredzocalo_x_techootro\n",
      "new_paredpreb_x_techootro\n",
      "new_pareddes_x_techoentrepiso\n",
      "new_pareddes_x_techocane\n",
      "new_pareddes_x_techootro\n",
      "new_paredmad_x_techocane\n",
      "new_paredmad_x_techootro\n",
      "new_paredzinc_x_techoentrepiso\n",
      "new_paredzinc_x_techocane\n",
      "new_paredzinc_x_techootro\n",
      "new_paredfibras_x_techoentrepiso\n",
      "new_paredfibras_x_techootro\n",
      "new_paredother_x_techoentrepiso\n",
      "new_paredother_x_techocane\n",
      "new_paredother_x_techootro\n",
      "new_paredblolad_x_pisocemento_x_techocane\n",
      "new_paredblolad_x_pisocemento_x_techootro\n",
      "new_paredblolad_x_pisoother_x_techoentrepiso\n",
      "new_paredblolad_x_pisoother_x_techocane\n",
      "new_paredblolad_x_pisoother_x_techootro\n",
      "new_paredblolad_x_pisonatur_x_techozinc\n",
      "new_paredblolad_x_pisonatur_x_techoentrepiso\n",
      "new_paredblolad_x_pisonatur_x_techocane\n",
      "new_paredblolad_x_pisonatur_x_techootro\n",
      "new_paredblolad_x_pisonotiene_x_techozinc\n",
      "new_paredblolad_x_pisonotiene_x_techoentrepiso\n",
      "new_paredblolad_x_pisonotiene_x_techocane\n",
      "new_paredblolad_x_pisonotiene_x_techootro\n",
      "new_paredblolad_x_pisomadera_x_techocane\n",
      "new_paredblolad_x_pisomadera_x_techootro\n",
      "new_paredzocalo_x_pisomoscer_x_techoentrepiso\n",
      "new_paredzocalo_x_pisomoscer_x_techocane\n",
      "new_paredzocalo_x_pisomoscer_x_techootro\n",
      "new_paredzocalo_x_pisocemento_x_techoentrepiso\n",
      "new_paredzocalo_x_pisocemento_x_techocane\n",
      "new_paredzocalo_x_pisocemento_x_techootro\n",
      "new_paredzocalo_x_pisoother_x_techozinc\n",
      "new_paredzocalo_x_pisoother_x_techoentrepiso\n",
      "new_paredzocalo_x_pisoother_x_techocane\n",
      "new_paredzocalo_x_pisoother_x_techootro\n",
      "new_paredzocalo_x_pisonatur_x_techozinc\n",
      "new_paredzocalo_x_pisonatur_x_techoentrepiso\n",
      "new_paredzocalo_x_pisonatur_x_techocane\n",
      "new_paredzocalo_x_pisonatur_x_techootro\n",
      "new_paredzocalo_x_pisonotiene_x_techoentrepiso\n",
      "new_paredzocalo_x_pisonotiene_x_techocane\n",
      "new_paredzocalo_x_pisonotiene_x_techootro\n",
      "new_paredzocalo_x_pisomadera_x_techoentrepiso\n",
      "new_paredzocalo_x_pisomadera_x_techocane\n",
      "new_paredzocalo_x_pisomadera_x_techootro\n",
      "new_paredpreb_x_pisocemento_x_techoentrepiso\n",
      "new_paredpreb_x_pisocemento_x_techocane\n",
      "new_paredpreb_x_pisocemento_x_techootro\n",
      "new_paredpreb_x_pisoother_x_techoentrepiso\n",
      "new_paredpreb_x_pisoother_x_techocane\n",
      "new_paredpreb_x_pisoother_x_techootro\n",
      "new_paredpreb_x_pisonatur_x_techozinc\n",
      "new_paredpreb_x_pisonatur_x_techoentrepiso\n",
      "new_paredpreb_x_pisonatur_x_techocane\n",
      "new_paredpreb_x_pisonatur_x_techootro\n",
      "new_paredpreb_x_pisonotiene_x_techozinc\n",
      "new_paredpreb_x_pisonotiene_x_techoentrepiso\n",
      "new_paredpreb_x_pisonotiene_x_techocane\n",
      "new_paredpreb_x_pisonotiene_x_techootro\n",
      "new_paredpreb_x_pisomadera_x_techoentrepiso\n",
      "new_paredpreb_x_pisomadera_x_techocane\n",
      "new_paredpreb_x_pisomadera_x_techootro\n",
      "new_pareddes_x_pisomoscer_x_techozinc\n",
      "new_pareddes_x_pisomoscer_x_techoentrepiso\n",
      "new_pareddes_x_pisomoscer_x_techocane\n",
      "new_pareddes_x_pisomoscer_x_techootro\n",
      "new_pareddes_x_pisocemento_x_techoentrepiso\n",
      "new_pareddes_x_pisocemento_x_techocane\n",
      "new_pareddes_x_pisocemento_x_techootro\n",
      "new_pareddes_x_pisoother_x_techozinc\n",
      "new_pareddes_x_pisoother_x_techoentrepiso\n",
      "new_pareddes_x_pisoother_x_techocane\n",
      "new_pareddes_x_pisoother_x_techootro\n",
      "new_pareddes_x_pisonatur_x_techozinc\n",
      "new_pareddes_x_pisonatur_x_techoentrepiso\n",
      "new_pareddes_x_pisonatur_x_techocane\n",
      "new_pareddes_x_pisonatur_x_techootro\n",
      "new_pareddes_x_pisonotiene_x_techoentrepiso\n",
      "new_pareddes_x_pisonotiene_x_techocane\n",
      "new_pareddes_x_pisonotiene_x_techootro\n",
      "new_pareddes_x_pisomadera_x_techozinc\n",
      "new_pareddes_x_pisomadera_x_techoentrepiso\n",
      "new_pareddes_x_pisomadera_x_techocane\n",
      "new_pareddes_x_pisomadera_x_techootro\n",
      "new_paredmad_x_pisomoscer_x_techocane\n",
      "new_paredmad_x_pisomoscer_x_techootro\n",
      "new_paredmad_x_pisocemento_x_techoentrepiso\n",
      "new_paredmad_x_pisocemento_x_techocane\n",
      "new_paredmad_x_pisocemento_x_techootro\n",
      "new_paredmad_x_pisoother_x_techozinc\n",
      "new_paredmad_x_pisoother_x_techoentrepiso\n",
      "new_paredmad_x_pisoother_x_techocane\n",
      "new_paredmad_x_pisoother_x_techootro\n",
      "new_paredmad_x_pisonatur_x_techozinc\n",
      "new_paredmad_x_pisonatur_x_techoentrepiso\n",
      "new_paredmad_x_pisonatur_x_techocane\n",
      "new_paredmad_x_pisonatur_x_techootro\n",
      "new_paredmad_x_pisonotiene_x_techoentrepiso\n",
      "new_paredmad_x_pisonotiene_x_techocane\n",
      "new_paredmad_x_pisonotiene_x_techootro\n",
      "new_paredmad_x_pisomadera_x_techocane\n",
      "new_paredzinc_x_pisomoscer_x_techoentrepiso\n",
      "new_paredzinc_x_pisomoscer_x_techocane\n",
      "new_paredzinc_x_pisomoscer_x_techootro\n",
      "new_paredzinc_x_pisocemento_x_techoentrepiso\n",
      "new_paredzinc_x_pisocemento_x_techocane\n",
      "new_paredzinc_x_pisocemento_x_techootro\n",
      "new_paredzinc_x_pisoother_x_techozinc\n",
      "new_paredzinc_x_pisoother_x_techoentrepiso\n",
      "new_paredzinc_x_pisoother_x_techocane\n",
      "new_paredzinc_x_pisoother_x_techootro\n",
      "new_paredzinc_x_pisonatur_x_techozinc\n",
      "new_paredzinc_x_pisonatur_x_techoentrepiso\n",
      "new_paredzinc_x_pisonatur_x_techocane\n",
      "new_paredzinc_x_pisonatur_x_techootro\n",
      "new_paredzinc_x_pisonotiene_x_techoentrepiso\n",
      "new_paredzinc_x_pisonotiene_x_techocane\n",
      "new_paredzinc_x_pisonotiene_x_techootro\n",
      "new_paredzinc_x_pisomadera_x_techoentrepiso\n",
      "new_paredzinc_x_pisomadera_x_techocane\n",
      "new_paredzinc_x_pisomadera_x_techootro\n",
      "new_paredfibras_x_pisomoscer_x_techoentrepiso\n",
      "new_paredfibras_x_pisomoscer_x_techocane\n",
      "new_paredfibras_x_pisomoscer_x_techootro\n",
      "new_paredfibras_x_pisocemento_x_techoentrepiso\n",
      "new_paredfibras_x_pisocemento_x_techocane\n",
      "new_paredfibras_x_pisocemento_x_techootro\n",
      "new_paredfibras_x_pisoother_x_techozinc\n",
      "new_paredfibras_x_pisoother_x_techoentrepiso\n",
      "new_paredfibras_x_pisoother_x_techocane\n",
      "new_paredfibras_x_pisoother_x_techootro\n",
      "new_paredfibras_x_pisonatur_x_techozinc\n",
      "new_paredfibras_x_pisonatur_x_techoentrepiso\n",
      "new_paredfibras_x_pisonatur_x_techocane\n",
      "new_paredfibras_x_pisonatur_x_techootro\n",
      "new_paredfibras_x_pisonotiene_x_techozinc\n",
      "new_paredfibras_x_pisonotiene_x_techoentrepiso\n",
      "new_paredfibras_x_pisonotiene_x_techocane\n",
      "new_paredfibras_x_pisonotiene_x_techootro\n",
      "new_paredfibras_x_pisomadera_x_techozinc\n",
      "new_paredfibras_x_pisomadera_x_techoentrepiso\n",
      "new_paredfibras_x_pisomadera_x_techocane\n",
      "new_paredfibras_x_pisomadera_x_techootro\n",
      "new_paredother_x_pisomoscer_x_techozinc\n",
      "new_paredother_x_pisomoscer_x_techoentrepiso\n",
      "new_paredother_x_pisomoscer_x_techocane\n",
      "new_paredother_x_pisomoscer_x_techootro\n",
      "new_paredother_x_pisocemento_x_techoentrepiso\n",
      "new_paredother_x_pisocemento_x_techocane\n",
      "new_paredother_x_pisocemento_x_techootro\n",
      "new_paredother_x_pisoother_x_techozinc\n",
      "new_paredother_x_pisoother_x_techoentrepiso\n",
      "new_paredother_x_pisoother_x_techocane\n",
      "new_paredother_x_pisoother_x_techootro\n",
      "new_paredother_x_pisonatur_x_techozinc\n",
      "new_paredother_x_pisonatur_x_techoentrepiso\n",
      "new_paredother_x_pisonatur_x_techocane\n",
      "new_paredother_x_pisonatur_x_techootro\n",
      "new_paredother_x_pisonotiene_x_techozinc\n",
      "new_paredother_x_pisonotiene_x_techoentrepiso\n",
      "new_paredother_x_pisonotiene_x_techocane\n",
      "new_paredother_x_pisonotiene_x_techootro\n",
      "new_paredother_x_pisomadera_x_techozinc\n",
      "new_paredother_x_pisomadera_x_techoentrepiso\n",
      "new_paredother_x_pisomadera_x_techocane\n",
      "new_paredother_x_pisomadera_x_techootro\n"
     ]
    }
   ],
   "source": [
    "cols_with_only_one_value = []\n",
    "for col in df_train.columns:\n",
    "    if col == 'Target':\n",
    "        continue\n",
    "    if df_train[col].value_counts().shape[0] == 1 or df_test[col].value_counts().shape[0] == 1:\n",
    "        print(col)\n",
    "        cols_with_only_one_value.append(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48dc7797",
   "metadata": {},
   "source": [
    "- Let's remove them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4e5f0460",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop(cols_with_only_one_value, axis=1, inplace=True)\n",
    "df_test.drop(cols_with_only_one_value, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7d2a4e",
   "metadata": {},
   "source": [
    "### Check whether both train and test have same features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a81df1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_train = np.array(sorted([col for col in df_train.columns if col != 'Target']))\n",
    "cols_test = np.array(sorted(df_test.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d58ca63f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(cols_train == cols_test).sum() == len(cols_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b1fe9d",
   "metadata": {},
   "source": [
    "- Good, Let's move!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c811b5",
   "metadata": {},
   "source": [
    "## 2.4 aggregation features\n",
    "- In this competition, each samples are member of spectific household(idhogar). So let's aggregate based on 'idhogar' values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d83761",
   "metadata": {},
   "source": [
    "### Aggregation for family features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "28f8c544",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_min(x):\n",
    "    return x.max() - x.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ffd696f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 15/15 [00:14<00:00,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new aggregate train set has 2988 rows, and 105 features\n",
      "new aggregate test set has 7352 rows, and 105 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "agg_train = pd.DataFrame()\n",
    "agg_test = pd.DataFrame()\n",
    "\n",
    "for item in tqdm(family_size_features):\n",
    "    for i, function in enumerate(['mean','std','min','max','sum', 'count', max_min]):\n",
    "        group_train = df_train[item].groupby(df_train['idhogar']).agg(function)\n",
    "        group_test = df_test[item].groupby(df_test['idhogar']).agg(function)\n",
    "        if i == 6:\n",
    "            new_col = item + '_new_' + 'max_min'\n",
    "        else:\n",
    "            new_col = item + '_new_' + function\n",
    "        agg_train[new_col] = group_train\n",
    "        agg_test[new_col] = group_test\n",
    "\n",
    "print('new aggregate train set has {} rows, and {} features'.format(agg_train.shape[0], agg_train.shape[1]))\n",
    "print('new aggregate test set has {} rows, and {} features'.format(agg_test.shape[0], agg_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3cadc6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 47/47 [00:00<00:00, 53.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new aggregate train set has 2988 rows, and 199 features\n",
      "new aggregate test set has 7352 rows, and 199 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "aggr_list = ['rez_esc', 'dis', 'male', 'female', \n",
    "                  'estadocivil1', 'estadocivil2', 'estadocivil3', 'estadocivil4', 'estadocivil5', 'estadocivil6', 'estadocivil7', \n",
    "                  'parentesco2', 'parentesco3', 'parentesco4', 'parentesco5', 'parentesco6', 'parentesco7', 'parentesco8', 'parentesco9', 'parentesco10', \n",
    "                  'parentesco11', 'parentesco12',\n",
    "                  'instlevel1', 'instlevel2', 'instlevel3', 'instlevel4', 'instlevel5', 'instlevel6', 'instlevel7', 'instlevel8', 'instlevel9',\n",
    "                 'epared1', 'epared2', 'epared3', 'etecho1', 'etecho2', 'etecho3', 'eviv1', 'eviv2', 'eviv3', 'refrig', 'television', 'mobilephone',\n",
    "            'area1', 'area2', 'v18q', 'edjef']\n",
    "\n",
    "\n",
    "\n",
    "for item in tqdm(aggr_list):\n",
    "    for function in ['count', 'sum']:\n",
    "        group_train = df_train[item].groupby(df_train['idhogar']).agg(function)\n",
    "        group_test = df_test[item].groupby(df_test['idhogar']).agg(function)\n",
    "        new_col = item + '_new1_' + function\n",
    "        agg_train[new_col] = group_train\n",
    "        agg_test[new_col] = group_test\n",
    "print('new aggregate train set has {} rows, and {} features'.format(agg_train.shape[0], agg_train.shape[1]))\n",
    "print('new aggregate test set has {} rows, and {} features'.format(agg_test.shape[0], agg_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ca201abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 9/9 [00:09<00:00,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new aggregate train set has 2988 rows, and 208 features\n",
      "new aggregate test set has 7352 rows, and 208 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "aggr_list = ['escolari', 'age', 'escolari_age', 'dependency', 'bedrooms', 'overcrowding', 'rooms', 'qmobilephone', 'v18q1']\n",
    "\n",
    "for item in tqdm(aggr_list):\n",
    "    for function in ['mean','std','min','max','sum', 'count', max_min]:\n",
    "        group_train = df_train[item].groupby(df_train['idhogar']).agg(function)\n",
    "        group_test = df_test[item].groupby(df_test['idhogar']).agg(function)\n",
    "        if i == 6:\n",
    "            new_col = item + '_new2_' + 'max_min'\n",
    "        else:\n",
    "            new_col = item + '_new2_' + function\n",
    "        agg_train[new_col] = group_train\n",
    "        agg_test[new_col] = group_test\n",
    "\n",
    "print('new aggregate train set has {} rows, and {} features'.format(agg_train.shape[0], agg_train.shape[1]))\n",
    "print('new aggregate test set has {} rows, and {} features'.format(agg_test.shape[0], agg_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "260f6398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (9557, 724) test shape: (23856, 723)\n"
     ]
    }
   ],
   "source": [
    "agg_test = agg_test.reset_index()\n",
    "agg_train = agg_train.reset_index()\n",
    "\n",
    "train_agg = pd.merge(df_train, agg_train, on='idhogar')\n",
    "test = pd.merge(df_test, agg_test, on='idhogar')\n",
    "\n",
    "#fill all na as 0\n",
    "train_agg.fillna(value=0, inplace=True)\n",
    "test.fillna(value=0, inplace=True)\n",
    "\n",
    "print('train shape:', train_agg.shape, 'test shape:', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8b0d5769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (9557, 1006) test shape: (23856, 1005)\n"
     ]
    }
   ],
   "source": [
    "aggr_list = ['rez_esc', 'dis', 'male', 'female', \n",
    "                  'estadocivil1', 'estadocivil2', 'estadocivil3', 'estadocivil4', 'estadocivil5', 'estadocivil6', 'estadocivil7', \n",
    "                  'parentesco2', 'parentesco3', 'parentesco4', 'parentesco5', 'parentesco6', 'parentesco7', 'parentesco8', 'parentesco9', 'parentesco10', \n",
    "                  'parentesco11', 'parentesco12',\n",
    "                  'instlevel1', 'instlevel2', 'instlevel3', 'instlevel4', 'instlevel5', 'instlevel6', 'instlevel7', 'instlevel8', 'instlevel9',\n",
    "                 'epared1', 'epared2', 'epared3', 'etecho1', 'etecho2', 'etecho3', 'eviv1', 'eviv2', 'eviv3', 'refrig', 'television', 'mobilephone',\n",
    "            'area1', 'area2', 'v18q', 'edjef']\n",
    "    \n",
    "for lugar in ['lugar1', 'lugar2', 'lugar3', 'lugar4', 'lugar5', 'lugar6']:\n",
    "    group_train = df_train[[lugar, 'idhogar'] + aggr_list].groupby([lugar, 'idhogar']).sum().reset_index()\n",
    "    group_train.columns = [lugar, 'idhogar'] + ['new3_{}_idhogar_{}'.format(lugar, col) for col in group_train][2:]\n",
    "\n",
    "    group_test = df_test[[lugar, 'idhogar'] + aggr_list].groupby([lugar, 'idhogar']).sum().reset_index()\n",
    "    group_test.columns = [lugar, 'idhogar'] + ['new3_{}_idhogar_{}'.format(lugar, col) for col in group_test][2:]\n",
    "\n",
    "    train_agg = pd.merge(train_agg, group_train, on=[lugar, 'idhogar'])\n",
    "    test = pd.merge(test, group_test, on=[lugar, 'idhogar'])\n",
    "    \n",
    "print('train shape:', train_agg.shape, 'test shape:', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d97be38f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (9557, 1288) test shape: (23856, 1287)\n"
     ]
    }
   ],
   "source": [
    "aggr_list = ['rez_esc', 'dis', 'male', 'female', \n",
    "                  'estadocivil1', 'estadocivil2', 'estadocivil3', 'estadocivil4', 'estadocivil5', 'estadocivil6', 'estadocivil7', \n",
    "                  'parentesco2', 'parentesco3', 'parentesco4', 'parentesco5', 'parentesco6', 'parentesco7', 'parentesco8', 'parentesco9', 'parentesco10', \n",
    "                  'parentesco11', 'parentesco12',\n",
    "                  'instlevel1', 'instlevel2', 'instlevel3', 'instlevel4', 'instlevel5', 'instlevel6', 'instlevel7', 'instlevel8', 'instlevel9',\n",
    "                 'epared1', 'epared2', 'epared3', 'etecho1', 'etecho2', 'etecho3', 'eviv1', 'eviv2', 'eviv3', 'refrig', 'television', 'mobilephone',\n",
    "            'area1', 'area2', 'v18q', 'edjef']\n",
    "    \n",
    "for lugar in ['lugar1', 'lugar2', 'lugar3', 'lugar4', 'lugar5', 'lugar6']:\n",
    "    group_train = df_train[[lugar, 'idhogar'] + aggr_list].groupby([lugar, 'idhogar']).sum().reset_index()\n",
    "    group_train.columns = [lugar, 'idhogar'] + ['new4_{}_idhogar_{}'.format(lugar, col) for col in group_train][2:]\n",
    "\n",
    "    group_test = df_test[[lugar, 'idhogar'] + aggr_list].groupby([lugar, 'idhogar']).sum().reset_index()\n",
    "    group_test.columns = [lugar, 'idhogar'] + ['new4_{}_idhogar_{}'.format(lugar, col) for col in group_test][2:]\n",
    "\n",
    "    train_agg = pd.merge(train_agg, group_train, on=[lugar, 'idhogar'])\n",
    "    test = pd.merge(test, group_test, on=[lugar, 'idhogar'])\n",
    "    \n",
    "print('train shape:', train_agg.shape, 'test shape:', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d4edbe8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 7/7 [04:59<00:00, 42.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (9557, 3262) test shape: (23856, 3261)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cols_nums = ['age', 'meaneduc', 'dependency', \n",
    "             'hogar_nin', 'hogar_adul', 'hogar_mayor', 'hogar_total',\n",
    "             'bedrooms', 'overcrowding']\n",
    "\n",
    "for function in tqdm(['mean','std','min','max','sum', 'count', max_min]):\n",
    "    for lugar in ['lugar1', 'lugar2', 'lugar3', 'lugar4', 'lugar5', 'lugar6']:\n",
    "        group_train = df_train[[lugar, 'idhogar'] + aggr_list].groupby([lugar, 'idhogar']).agg(function).reset_index()\n",
    "        group_train.columns = [lugar, 'idhogar'] + ['new5_{}_idhogar_{}_{}'.format(lugar, col, function) for col in group_train][2:]\n",
    "\n",
    "        group_test = df_test[[lugar, 'idhogar'] + aggr_list].groupby([lugar, 'idhogar']).agg(function).reset_index()\n",
    "        group_test.columns = [lugar, 'idhogar'] + ['new5_{}_idhogar_{}_{}'.format(lugar, col, function) for col in group_test][2:]\n",
    "\n",
    "        train_agg = pd.merge(train_agg, group_train, on=[lugar, 'idhogar'])\n",
    "        test = pd.merge(test, group_test, on=[lugar, 'idhogar'])\n",
    "        \n",
    "print('train shape:', train_agg.shape, 'test shape:', test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec0f5b6",
   "metadata": {},
   "source": [
    "- According to data descriptions,ONLY the heads of household are used in scoring. /\n",
    "- All household members are included in test + the sample submission, but only heads of households are scored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "48c76e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_agg.query('parentesco1==1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "33caa37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['dependency'].replace(np.inf, 0, inplace=True)\n",
    "test['dependency'].replace(np.inf, 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "08b7f6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = test[['Id']]\n",
    "\n",
    "#Remove useless feature to reduce dimension\n",
    "train.drop(columns=['idhogar','Id', 'agesq', 'hogar_adul', 'SQBescolari', 'SQBage', 'SQBhogar_total', 'SQBedjefe', 'SQBhogar_nin', 'SQBovercrowding', 'SQBdependency', 'SQBmeaned'], inplace=True)\n",
    "test.drop(columns=['idhogar','Id',  'agesq', 'hogar_adul', 'SQBescolari', 'SQBage', 'SQBhogar_total', 'SQBedjefe', 'SQBhogar_nin', 'SQBovercrowding', 'SQBdependency', 'SQBmeaned'], inplace=True)\n",
    "\n",
    "correlation = train.corr()\n",
    "correlation = correlation['Target'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4a4a9dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_data size (2973, 3250) (23856, 3249)\n"
     ]
    }
   ],
   "source": [
    "print('final_data size', train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a97efa01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most 20 positive feature: \n",
      "Target                                1.000000\n",
      "new5_lugar3_idhogar_edjef_max         0.334254\n",
      "new5_lugar2_idhogar_edjef_max         0.334254\n",
      "new5_lugar5_idhogar_edjef_max         0.334254\n",
      "new5_lugar4_idhogar_edjef_max         0.334254\n",
      "new5_lugar6_idhogar_edjef_max         0.334254\n",
      "new5_lugar1_idhogar_edjef_max         0.334254\n",
      "new5_lugar2_idhogar_edjef_mean        0.333873\n",
      "new5_lugar4_idhogar_edjef_mean        0.333873\n",
      "new5_lugar3_idhogar_edjef_mean        0.333873\n",
      "new5_lugar1_idhogar_edjef_mean        0.333873\n",
      "new5_lugar5_idhogar_edjef_mean        0.333873\n",
      "new5_lugar6_idhogar_edjef_mean        0.333873\n",
      "new5_lugar3_idhogar_edjef_min         0.333791\n",
      "new5_lugar4_idhogar_edjef_min         0.333791\n",
      "new5_lugar5_idhogar_edjef_min         0.333791\n",
      "new5_lugar6_idhogar_edjef_min         0.333791\n",
      "edjef                                 0.333791\n",
      "new5_lugar2_idhogar_edjef_min         0.333791\n",
      "new5_lugar1_idhogar_edjef_min         0.333791\n",
      "escolari                              0.333791\n",
      "meaneduc                              0.331489\n",
      "new5_lugar5_idhogar_instlevel8_max    0.317815\n",
      "new5_lugar2_idhogar_instlevel8_max    0.317815\n",
      "new5_lugar6_idhogar_instlevel8_max    0.317815\n",
      "new5_lugar3_idhogar_instlevel8_max    0.317815\n",
      "new5_lugar1_idhogar_instlevel8_max    0.317815\n",
      "new5_lugar4_idhogar_instlevel8_max    0.317815\n",
      "phones-per-capita                     0.299026\n",
      "new5_lugar6_idhogar_instlevel8_std    0.298251\n",
      "new5_lugar5_idhogar_instlevel8_std    0.298251\n",
      "new5_lugar1_idhogar_instlevel8_std    0.298251\n",
      "new5_lugar2_idhogar_instlevel8_std    0.298251\n",
      "new5_lugar3_idhogar_instlevel8_std    0.298251\n",
      "new5_lugar4_idhogar_instlevel8_std    0.298251\n",
      "new_epared3_x_eviv3                   0.298196\n",
      "cielorazo                             0.295249\n",
      "new4_lugar2_idhogar_instlevel8        0.294277\n",
      "instlevel8_new1_sum                   0.294277\n",
      "new4_lugar1_idhogar_instlevel8        0.294277\n",
      "Name: Target, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(f'The most 20 positive feature: \\n{correlation.head(40)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f5c24d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most 20 negative feature: \n",
      "new5_lugar5_idhogar_television_<function max_min at 0x7fd05b87d1f0>    NaN\n",
      "new5_lugar5_idhogar_mobilephone_<function max_min at 0x7fd05b87d1f0>   NaN\n",
      "new5_lugar5_idhogar_area1_<function max_min at 0x7fd05b87d1f0>         NaN\n",
      "new5_lugar5_idhogar_area2_<function max_min at 0x7fd05b87d1f0>         NaN\n",
      "new5_lugar5_idhogar_v18q_<function max_min at 0x7fd05b87d1f0>          NaN\n",
      "new5_lugar6_idhogar_epared1_<function max_min at 0x7fd05b87d1f0>       NaN\n",
      "new5_lugar6_idhogar_epared2_<function max_min at 0x7fd05b87d1f0>       NaN\n",
      "new5_lugar6_idhogar_epared3_<function max_min at 0x7fd05b87d1f0>       NaN\n",
      "new5_lugar6_idhogar_etecho1_<function max_min at 0x7fd05b87d1f0>       NaN\n",
      "new5_lugar6_idhogar_etecho2_<function max_min at 0x7fd05b87d1f0>       NaN\n",
      "new5_lugar6_idhogar_etecho3_<function max_min at 0x7fd05b87d1f0>       NaN\n",
      "new5_lugar6_idhogar_eviv1_<function max_min at 0x7fd05b87d1f0>         NaN\n",
      "new5_lugar6_idhogar_eviv2_<function max_min at 0x7fd05b87d1f0>         NaN\n",
      "new5_lugar6_idhogar_eviv3_<function max_min at 0x7fd05b87d1f0>         NaN\n",
      "new5_lugar6_idhogar_refrig_<function max_min at 0x7fd05b87d1f0>        NaN\n",
      "new5_lugar6_idhogar_television_<function max_min at 0x7fd05b87d1f0>    NaN\n",
      "new5_lugar6_idhogar_mobilephone_<function max_min at 0x7fd05b87d1f0>   NaN\n",
      "new5_lugar6_idhogar_area1_<function max_min at 0x7fd05b87d1f0>         NaN\n",
      "new5_lugar6_idhogar_area2_<function max_min at 0x7fd05b87d1f0>         NaN\n",
      "new5_lugar6_idhogar_v18q_<function max_min at 0x7fd05b87d1f0>          NaN\n",
      "Name: Target, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(f'The most 20 negative feature: \\n{correlation.tail(20)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32a8bd5",
   "metadata": {},
   "source": [
    "# 4. Feature selection using shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "984b972b",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_cat_features = [col for col in train.columns if train[col].value_counts().shape[0] == 2]\n",
    "object_features = ['edjefe', 'edjefa']\n",
    "\n",
    "categorical_feats = binary_cat_features + object_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "11660149",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_macroF1_lgb(truth, predictions):  \n",
    "    # this follows the discussion in https://github.com/Microsoft/LightGBM/issues/1483\n",
    "    pred_labels = predictions.reshape(len(np.unique(truth)),-1).argmax(axis=0)\n",
    "    f1 = f1_score(truth, pred_labels, average='macro')\n",
    "    return ('macroF1', f1, True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c15851ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train['Target']\n",
    "train.drop(columns=['Target'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "32e4fc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_execution_time(start):\n",
    "    end = time.time()\n",
    "    hours, rem = divmod(end-start, 3600)\n",
    "    minutes, seconds = divmod(rem, 60)\n",
    "    print('*'*20, \"Execution ended in {:0>2}h {:0>2}m {:05.2f}s\".format(int(hours),int(minutes),seconds), '*'*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5d79c806",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_good_features_using_shap_LGB(params, SEED):\n",
    "    clf = lgb.LGBMClassifier(objective='multiclass',\n",
    "                             random_state=1989,\n",
    "                             max_depth=params['max_depth'], \n",
    "                             learning_rate=params['learning_rate'],  \n",
    "                             silent=True, \n",
    "                             metric='multi_logloss',\n",
    "                             n_jobs=-1, n_estimators=10000, \n",
    "                             class_weight='balanced',\n",
    "                             colsample_bytree = params['colsample_bytree'], \n",
    "                             min_split_gain= params['min_split_gain'], \n",
    "                             bagging_freq = params['bagging_freq'],\n",
    "                             min_child_weight=params['min_child_weight'],\n",
    "                             num_leaves = params['num_leaves'], \n",
    "                             subsample = params['subsample'],\n",
    "                             reg_alpha= params['reg_alpha'],\n",
    "                             reg_lambda= params['reg_lambda'],\n",
    "                             num_class=len(np.unique(y)),\n",
    "                             bagging_seed=SEED,\n",
    "                             seed=SEED,\n",
    "                            )\n",
    "\n",
    "    kfold = 5\n",
    "    kf = StratifiedKFold(n_splits=kfold, shuffle=True)\n",
    "    feat_importance_df  = pd.DataFrame()\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(train, y)):\n",
    "        print('='*30, '{} of {} folds'.format(i+1, kfold), '='*30)\n",
    "        start = time.time()\n",
    "        X_train, X_val = train.iloc[train_index], train.iloc[test_index]\n",
    "        y_train, y_val = y.iloc[train_index], y.iloc[test_index]\n",
    "        clf.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_val, y_val)], eval_metric=evaluate_macroF1_lgb, categorical_feature=categorical_feats,\n",
    "                early_stopping_rounds=500, verbose=500)\n",
    "        shap_values = shap.TreeExplainer(clf.booster_).shap_values(X_train)\n",
    "        fold_importance_df  = pd.DataFrame()\n",
    "        fold_importance_df['feature'] = X_train.columns\n",
    "        fold_importance_df['shap_values'] = abs(np.array(shap_values)[:, :].mean(1).mean(0))\n",
    "        fold_importance_df['feat_imp'] = clf.feature_importances_\n",
    "        feat_importance_df = pd.concat([feat_importance_df, fold_importance_df])\n",
    "        print_execution_time(start)\n",
    "\n",
    "    feat_importance_df_shap = feat_importance_df.groupby('feature').mean().sort_values('shap_values', ascending=False).reset_index()\n",
    "#     feat_importance_df_shap['shap_cumsum'] = feat_importance_df_shap['shap_values'].cumsum() / feat_importance_df_shap['shap_values'].sum()\n",
    "#     good_features = feat_importance_df_shap.loc[feat_importance_df_shap['shap_cumsum'] < 0.999].feature\n",
    "    return feat_importance_df_shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "84a40e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################## 1 of 50 iterations ########################################\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'lgb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [92]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m#\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m40\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m of \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m iterations\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(SEED\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, NUM_ITERATIONS), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m#\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m40\u001b[39m)\n\u001b[1;32m      5\u001b[0m params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice([\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]),\n\u001b[1;32m      6\u001b[0m          \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrand() \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.02\u001b[39m,\n\u001b[1;32m      7\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolsample_bytree\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrand() \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m0.5\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.5\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin_child_weight\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m100\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m20\u001b[39m\n\u001b[1;32m     15\u001b[0m          }\n\u001b[0;32m---> 16\u001b[0m temp_shap_df \u001b[38;5;241m=\u001b[39m \u001b[43mextract_good_features_using_shap_LGB\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSEED\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m total_shap_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([total_shap_df, temp_shap_df])\n",
      "Input \u001b[0;32mIn [91]\u001b[0m, in \u001b[0;36mextract_good_features_using_shap_LGB\u001b[0;34m(params, SEED)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_good_features_using_shap_LGB\u001b[39m(params, SEED):\n\u001b[0;32m----> 2\u001b[0m     clf \u001b[38;5;241m=\u001b[39m \u001b[43mlgb\u001b[49m\u001b[38;5;241m.\u001b[39mLGBMClassifier(objective\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      3\u001b[0m                              random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1989\u001b[39m,\n\u001b[1;32m      4\u001b[0m                              max_depth\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[1;32m      5\u001b[0m                              learning_rate\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m],  \n\u001b[1;32m      6\u001b[0m                              silent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[1;32m      7\u001b[0m                              metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmulti_logloss\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      8\u001b[0m                              n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10000\u001b[39m, \n\u001b[1;32m      9\u001b[0m                              class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     10\u001b[0m                              colsample_bytree \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolsample_bytree\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[1;32m     11\u001b[0m                              min_split_gain\u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin_split_gain\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[1;32m     12\u001b[0m                              bagging_freq \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbagging_freq\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     13\u001b[0m                              min_child_weight\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin_child_weight\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     14\u001b[0m                              num_leaves \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_leaves\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[1;32m     15\u001b[0m                              subsample \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubsample\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     16\u001b[0m                              reg_alpha\u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreg_alpha\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     17\u001b[0m                              reg_lambda\u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreg_lambda\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     18\u001b[0m                              num_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(np\u001b[38;5;241m.\u001b[39munique(y)),\n\u001b[1;32m     19\u001b[0m                              bagging_seed\u001b[38;5;241m=\u001b[39mSEED,\n\u001b[1;32m     20\u001b[0m                              seed\u001b[38;5;241m=\u001b[39mSEED,\n\u001b[1;32m     21\u001b[0m                             )\n\u001b[1;32m     23\u001b[0m     kfold \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[1;32m     24\u001b[0m     kf \u001b[38;5;241m=\u001b[39m StratifiedKFold(n_splits\u001b[38;5;241m=\u001b[39mkfold, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lgb' is not defined"
     ]
    }
   ],
   "source": [
    "total_shap_df  = pd.DataFrame()\n",
    "NUM_ITERATIONS = 50\n",
    "for SEED in range(NUM_ITERATIONS):\n",
    "    print('#'*40, '{} of {} iterations'.format(SEED+1, NUM_ITERATIONS), '#' * 40)\n",
    "    params = {'max_depth': np.random.choice([5, 6, 7, 8, 10, 12, -1]),\n",
    "             'learning_rate': np.random.rand() * 0.02,\n",
    "              'colsample_bytree': np.random.rand() * (1 - 0.5) + 0.5,\n",
    "              'subsample': np.random.rand() * (1 - 0.5) + 0.5,\n",
    "              'min_split_gain': np.random.rand() * 0.2,\n",
    "              'num_leaves': np.random.choice([32, 48, 64]),\n",
    "              'reg_alpha': np.random.rand() * 2,\n",
    "              'reg_lambda': np.random.rand() *2,\n",
    "              'bagging_freq': np.random.randint(4) +1,\n",
    "              'min_child_weight': np.random.randint(100) + 20\n",
    "             }\n",
    "    temp_shap_df = extract_good_features_using_shap_LGB(params, SEED)\n",
    "    total_shap_df = pd.concat([total_shap_df, temp_shap_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbec02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_sorted_df = total_shap_df.groupby('feature').mean().sort_values('shap_values', ascending=False).reset_index()\n",
    "feat_imp_sorted_df = total_shap_df.groupby('feature').mean().sort_values('feat_imp', ascending=False).reset_index()\n",
    "features_top_shap = shap_sorted_df['feature'][:500]\n",
    "features_top_feat_imp = feat_imp_sorted_df['feature'][:500]\n",
    "top_features = pd.Series(features_top_shap.tolist() + features_top_feat_imp.tolist())\n",
    "top_features = top_features.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63496e0",
   "metadata": {},
   "source": [
    "# 4. Model development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba30ec71",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train = train[top_features].copy()\n",
    "new_test = test[top_features].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95aada42",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('new_train shape:', new_train.shape, 'new_test shape:', new_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13350e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_categorical_feats = [col for col in top_features if col in categorical_feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb641ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LGB_OOF(params, categorical_feats, N_FOLDs, SEED=1989):\n",
    "    clf = lgb.LGBMClassifier(objective='multiclass',\n",
    "                             random_state=1989,\n",
    "                             max_depth=params['max_depth'], \n",
    "                             learning_rate=params['learning_rate'],  \n",
    "                             silent=True, \n",
    "                             metric='multi_logloss',\n",
    "                             n_jobs=-1, n_estimators=10000, \n",
    "                             class_weight='balanced',\n",
    "                             colsample_bytree = params['colsample_bytree'], \n",
    "                             min_split_gain= params['min_split_gain'], \n",
    "                             bagging_freq = params['bagging_freq'],\n",
    "                             min_child_weight=params['min_child_weight'],\n",
    "                             num_leaves = params['num_leaves'], \n",
    "                             subsample = params['subsample'],\n",
    "                             reg_alpha= params['reg_alpha'],\n",
    "                             reg_lambda= params['reg_lambda'],\n",
    "                             num_class=len(np.unique(y)),\n",
    "                             bagging_seed=SEED,\n",
    "                             seed=SEED,\n",
    "                            )\n",
    "\n",
    "    kfold = 10\n",
    "    kf = StratifiedKFold(n_splits=kfold, shuffle=True)\n",
    "    feat_importance_df  = pd.DataFrame()\n",
    "    predicts_result = []\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(new_train, y)):\n",
    "        print('='*30, '{} of {} folds'.format(i+1, kfold), '='*30)\n",
    "        start = time.time()\n",
    "        X_train, X_val = new_train.iloc[train_index], new_train.iloc[test_index]\n",
    "        y_train, y_val = y.iloc[train_index], y.iloc[test_index]\n",
    "        clf.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_val, y_val)], eval_metric=evaluate_macroF1_lgb,categorical_feature=new_categorical_feats,\n",
    "                early_stopping_rounds=500, verbose=500)\n",
    "        shap_values = shap.TreeExplainer(clf.booster_).shap_values(X_train)\n",
    "        fold_importance_df  = pd.DataFrame()\n",
    "        fold_importance_df['feature'] = X_train.columns\n",
    "        fold_importance_df['shap_values'] = abs(np.array(shap_values)[:, :].mean(1).mean(0))\n",
    "        fold_importance_df['feat_imp'] = clf.feature_importances_\n",
    "        feat_importance_df = pd.concat([feat_importance_df, fold_importance_df])\n",
    "        predicts_result.append(clf.predict(new_test))\n",
    "        print_execution_time(start)\n",
    "    return predicts_result, feat_importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a906cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'max_depth': 6,\n",
    "         'learning_rate': 0.002,\n",
    "          'colsample_bytree': 0.8,\n",
    "          'subsample': 0.8,\n",
    "          'min_split_gain': 0.02,\n",
    "          'num_leaves': 48,\n",
    "          'reg_alpha': 0.04,\n",
    "          'reg_lambda': 0.073,\n",
    "          'bagging_freq': 2,\n",
    "          'min_child_weight': 40\n",
    "         }\n",
    "\n",
    "N_Folds = 20\n",
    "SEED = 1989\n",
    "predicts_result, feat_importance_df = LGB_OOF(params, new_categorical_feats, N_Folds, SEED=1989)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75ee42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(20, 20))\n",
    "feat_importance_df_shap = feat_importance_df.groupby('feature').mean().sort_values('shap_values', ascending=False).reset_index()\n",
    "\n",
    "num_features = 50\n",
    "sns.barplot(x=feat_importance_df_shap.shap_values[:num_features], y=feat_importance_df_shap.feature[:num_features], ax=ax[0])\n",
    "ax[0].set_title('Feature importance based on shap values')\n",
    "\n",
    "feat_importance_df = feat_importance_df.groupby('feature').mean().sort_values('feat_imp', ascending=False).reset_index()\n",
    "\n",
    "num_features = 50\n",
    "sns.barplot(x=feat_importance_df.shap_values[:num_features], y=feat_importance_df.feature[:num_features], ax=ax[1])\n",
    "ax[1].set_title('Feaure importance based on feature importance from lgbm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867e6458",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['Target'] = np.array(predicts_result).mean(axis=0).round().astype(int)\n",
    "submission.to_csv('submission_with_new_feature_set.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf17425",
   "metadata": {},
   "source": [
    "### Randomized serach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec332eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_param = None\n",
    "lowest_cv = 1000\n",
    "total_iteration = 100\n",
    "for i in range(total_iteration):\n",
    "    print('-'*20, 'For {} of {} iterations'.format(i+1, total_iteration), '-'*20)\n",
    "    learning_rate = np.random.rand() * 0.02\n",
    "    n_folds = 3\n",
    "\n",
    "    num_class = len(np.unique(y))\n",
    "\n",
    "    params = {}\n",
    "    params['application'] = 'multiclass'\n",
    "    params['metric'] = 'multi_logloss'\n",
    "    params['num_class'] = num_class\n",
    "    params['class_weight'] = 'balanced'\n",
    "    params['num_leaves'] = np.random.randint(24, 48)\n",
    "    params['max_depth'] = np.random.randint(5, 8)\n",
    "    params['min_child_weight'] = np.random.randint(5, 50)\n",
    "    params['min_split_gain'] = np.random.rand() * 0.09\n",
    "    params['colsample_bytree'] = np.random.rand() * (0.9 - 0.1) + 0.1\n",
    "    params['subsample'] = np.random.rand() * (1 - 0.8) + 0.8\n",
    "    params['bagging_freq'] = np.random.randint(1, 5)\n",
    "    params['bagging_seed'] = np.random.randint(1, 5)\n",
    "    params['reg_alpha'] = np.random.rand() * 2\n",
    "    params['reg_lambda'] = np.random.rand() * 2\n",
    "    params['learning_rate'] = np.random.rand() * 0.02\n",
    "    params['seed']  =1989\n",
    "\n",
    "    d_train = lgb.Dataset(data=new_train, label=y.values-1, categorical_feature=new_categorical_feats, free_raw_data=False)\n",
    "    cv_results = lgb.cv(params=params, train_set=d_train, num_boost_round=10000, categorical_feature=new_categorical_feats,\n",
    "                        nfold=n_folds, stratified=True, shuffle=True, early_stopping_rounds=1, verbose_eval=1000)\n",
    "\n",
    "    min_cv_results = min(cv_results['multi_logloss-mean'])\n",
    "\n",
    "    if min_cv_results < lowest_cv:\n",
    "        lowest_cv = min_cv_results\n",
    "        optimized_param = params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28fd590",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_Folds = 20\n",
    "SEED = 1989\n",
    "predicts_result, feat_importance_df = LGB_OOF(optimized_param, new_categorical_feats, N_Folds, SEED=1989)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835e51cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['Target'] = np.array(predicts_result).mean(axis=0).round().astype(int)\n",
    "submission.to_csv('submission_shap_randomized_search.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c72b392",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1bf0389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting featuretools\n",
      "  Downloading featuretools-1.23.0-py3-none-any.whl (555 kB)\n",
      "\u001b[K     |████████████████████████████████| 555 kB 9.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: cloudpickle>=1.5.0 in /Users/gimhayun/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from featuretools) (2.1.0)\n",
      "Collecting distributed!=2022.10.1,>=2022.2.0\n",
      "  Downloading distributed-2023.3.0-py3-none-any.whl (945 kB)\n",
      "\u001b[K     |████████████████████████████████| 945 kB 61.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.4.0 in /Users/gimhayun/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from featuretools) (1.5.4)\n",
      "Requirement already satisfied: psutil>=5.6.6 in /Users/gimhayun/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from featuretools) (5.9.1)\n",
      "Collecting numpy>=1.21.0\n",
      "  Using cached numpy-1.24.2-cp38-cp38-macosx_10_9_x86_64.whl (19.8 MB)\n",
      "Collecting dask[dataframe]!=2022.10.1,>=2022.2.0\n",
      "  Downloading dask-2023.3.0-py3-none-any.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 53.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting holidays>=0.13\n",
      "  Downloading holidays-0.21-py3-none-any.whl (230 kB)\n",
      "\u001b[K     |████████████████████████████████| 230 kB 75.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /Users/gimhayun/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from featuretools) (21.3)\n",
      "Requirement already satisfied: tqdm>=4.32.0 in /Users/gimhayun/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from featuretools) (4.64.0)\n",
      "Requirement already satisfied: pandas>=1.4.0 in /Users/gimhayun/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from featuretools) (1.4.2)\n",
      "Collecting woodwork[dask]>=0.18.0\n",
      "  Downloading woodwork-0.21.2-py3-none-any.whl (230 kB)\n",
      "\u001b[K     |████████████████████████████████| 230 kB 90.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting toolz>=0.8.2\n",
      "  Downloading toolz-0.12.0-py3-none-any.whl (55 kB)\n",
      "\u001b[K     |████████████████████████████████| 55 kB 9.9 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.3.1 in /Users/gimhayun/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from dask[dataframe]!=2022.10.1,>=2022.2.0->featuretools) (5.4.1)\n",
      "Collecting fsspec>=0.6.0\n",
      "  Downloading fsspec-2023.3.0-py3-none-any.whl (145 kB)\n",
      "\u001b[K     |████████████████████████████████| 145 kB 63.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: click>=7.0 in /Users/gimhayun/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from dask[dataframe]!=2022.10.1,>=2022.2.0->featuretools) (8.1.3)\n",
      "Collecting partd>=1.2.0\n",
      "  Downloading partd-1.3.0-py3-none-any.whl (18 kB)\n",
      "Collecting zict>=2.1.0\n",
      "  Downloading zict-2.2.0-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: urllib3>=1.24.3 in /Users/gimhayun/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from distributed!=2022.10.1,>=2022.2.0->featuretools) (1.26.9)\n",
      "Requirement already satisfied: jinja2>=2.10.3 in /Users/gimhayun/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from distributed!=2022.10.1,>=2022.2.0->featuretools) (3.1.2)\n",
      "Collecting sortedcontainers>=2.0.5\n",
      "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Collecting msgpack>=1.0.0\n",
      "  Downloading msgpack-1.0.5-cp38-cp38-macosx_10_9_x86_64.whl (73 kB)\n",
      "\u001b[K     |████████████████████████████████| 73 kB 6.6 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tornado>=6.0.3 in /Users/gimhayun/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from distributed!=2022.10.1,>=2022.2.0->featuretools) (6.1)\n",
      "Collecting locket>=1.0.0\n",
      "  Downloading locket-1.0.0-py2.py3-none-any.whl (4.4 kB)\n",
      "Collecting tblib>=1.6.0\n",
      "  Downloading tblib-1.7.0-py2.py3-none-any.whl (12 kB)\n",
      "Collecting backports.zoneinfo\n",
      "  Downloading backports.zoneinfo-0.2.1-cp38-cp38-macosx_10_14_x86_64.whl (35 kB)\n",
      "Collecting hijri-converter\n",
      "  Downloading hijri_converter-2.2.4-py3-none-any.whl (14 kB)\n",
      "Collecting convertdate>=2.3.0\n",
      "  Downloading convertdate-2.4.0-py3-none-any.whl (47 kB)\n",
      "\u001b[K     |████████████████████████████████| 47 kB 13.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting PyMeeus\n",
      "  Downloading PyMeeus-0.5.12.tar.gz (5.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.8 MB 53.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting korean-lunar-calendar\n",
      "  Downloading korean_lunar_calendar-0.3.1-py3-none-any.whl (9.0 kB)\n",
      "Requirement already satisfied: python-dateutil in /Users/gimhayun/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from holidays>=0.13->featuretools) (2.8.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/gimhayun/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from jinja2>=2.10.3->distributed!=2022.10.1,>=2022.2.0->featuretools) (2.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/gimhayun/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from packaging>=20.0->featuretools) (3.0.9)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/gimhayun/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from pandas>=1.4.0->featuretools) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/gimhayun/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from python-dateutil->holidays>=0.13->featuretools) (1.16.0)\n",
      "Collecting importlib-resources>=5.10.0\n",
      "  Downloading importlib_resources-5.12.0-py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: scikit-learn>=0.22 in /Users/gimhayun/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from woodwork[dask]>=0.18.0->featuretools) (0.23.2)\n",
      "Collecting pandas>=1.4.0\n",
      "  Downloading pandas-1.5.3-cp38-cp38-macosx_10_9_x86_64.whl (11.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.9 MB 42.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: zipp>=3.1.0 in /Users/gimhayun/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from importlib-resources>=5.10.0->woodwork[dask]>=0.18.0->featuretools) (3.8.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/gimhayun/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from scikit-learn>=0.22->woodwork[dask]>=0.18.0->featuretools) (3.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/gimhayun/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from scikit-learn>=0.22->woodwork[dask]>=0.18.0->featuretools) (1.1.0)\n",
      "Collecting heapdict\n",
      "  Downloading HeapDict-1.0.1-py3-none-any.whl (3.9 kB)\n",
      "Building wheels for collected packages: PyMeeus\n",
      "  Building wheel for PyMeeus (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for PyMeeus: filename=PyMeeus-0.5.12-py3-none-any.whl size=732018 sha256=d47d230db4c85c6d0cddb2dafdd86559c0f31168e23e2cf70a388bdd694e3c02\n",
      "  Stored in directory: /Users/gimhayun/Library/Caches/pip/wheels/c2/3a/3d/11734e652782d3f823a08aae1c452e887eb16349750cca3f8a\n",
      "Successfully built PyMeeus\n",
      "Installing collected packages: toolz, numpy, locket, partd, fsspec, PyMeeus, pandas, importlib-resources, heapdict, dask, zict, woodwork, tblib, sortedcontainers, msgpack, korean-lunar-calendar, hijri-converter, convertdate, backports.zoneinfo, holidays, distributed, featuretools\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.20.3\n",
      "    Uninstalling numpy-1.20.3:\n",
      "      Successfully uninstalled numpy-1.20.3\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.4.2\n",
      "    Uninstalling pandas-1.4.2:\n",
      "      Successfully uninstalled pandas-1.4.2\n",
      "  Attempting uninstall: importlib-resources\n",
      "    Found existing installation: importlib-resources 5.7.1\n",
      "    Uninstalling importlib-resources-5.7.1:\n",
      "      Successfully uninstalled importlib-resources-5.7.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "yellowbrick 1.3.post1 requires numpy<1.20,>=1.16.0, but you have numpy 1.24.2 which is incompatible.\n",
      "numba 0.54.1 requires numpy<1.21,>=1.17, but you have numpy 1.24.2 which is incompatible.\u001b[0m\n",
      "Successfully installed PyMeeus-0.5.12 backports.zoneinfo-0.2.1 convertdate-2.4.0 dask-2023.3.0 distributed-2023.3.0 featuretools-1.23.0 fsspec-2023.3.0 heapdict-1.0.1 hijri-converter-2.2.4 holidays-0.21 importlib-resources-5.12.0 korean-lunar-calendar-0.3.1 locket-1.0.0 msgpack-1.0.5 numpy-1.24.2 pandas-1.5.3 partd-1.3.0 sortedcontainers-2.4.0 tblib-1.7.0 toolz-0.12.0 woodwork-0.21.2 zict-2.2.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install featuretools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a35e1de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting shap\n",
      "  Downloading shap-0.41.0-cp38-cp38-macosx_10_9_x86_64.whl (436 kB)\n",
      "\u001b[K     |████████████████████████████████| 436 kB 7.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numba in /Users/gimhayun/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from shap) (0.54.1)\n",
      "Requirement already satisfied: cloudpickle in /Users/gimhayun/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from shap) (2.1.0)\n",
      "Requirement already satisfied: scipy in /Users/gimhayun/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from shap) (1.5.4)\n",
      "Requirement already satisfied: pandas in /Users/gimhayun/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from shap) (1.4.2)\n",
      "Requirement already satisfied: scikit-learn in /Users/gimhayun/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from shap) (0.23.2)\n",
      "Requirement already satisfied: tqdm>4.25.0 in /Users/gimhayun/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from shap) (4.64.0)\n",
      "Collecting slicer==0.0.7\n",
      "  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: numpy in /Users/gimhayun/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from shap) (1.24.2)\n",
      "Requirement already satisfied: packaging>20.9 in /Users/gimhayun/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from shap) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/gimhayun/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from packaging>20.9->shap) (3.0.9)\n",
      "Requirement already satisfied: setuptools in /Users/gimhayun/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from numba->shap) (61.2.0)\n",
      "Requirement already satisfied: llvmlite<0.38,>=0.37.0rc1 in /Users/gimhayun/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from numba->shap) (0.37.0)\n",
      "Collecting numpy\n",
      "  Using cached numpy-1.20.3-cp38-cp38-macosx_10_9_x86_64.whl (16.0 MB)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/gimhayun/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from pandas->shap) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/gimhayun/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from pandas->shap) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/gimhayun/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas->shap) (1.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/gimhayun/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from scikit-learn->shap) (3.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/gimhayun/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from scikit-learn->shap) (1.1.0)\n",
      "Installing collected packages: numpy, slicer, shap\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.24.2\n",
      "    Uninstalling numpy-1.24.2:\n",
      "      Successfully uninstalled numpy-1.24.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "yellowbrick 1.3.post1 requires numpy<1.20,>=1.16.0, but you have numpy 1.20.3 which is incompatible.\u001b[0m\n",
      "Successfully installed numpy-1.20.3 shap-0.41.0 slicer-0.0.7\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install shap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1d8d3f",
   "metadata": {},
   "source": [
    "pip install shap\n",
    "\n",
    "Installing collected packages: numpy, slicer, shap\n",
    "  Attempting uninstall: numpy\n",
    "    Found existing installation: numpy 1.24.2\n",
    "    Uninstalling numpy-1.24.2:\n",
    "      Successfully uninstalled numpy-1.24.2\n",
    "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
    "yellowbrick 1.3.post1 requires numpy<1.20,>=1.16.0, but you have numpy 1.20.3 which is incompatible.\n",
    "Successfully installed numpy-1.20.3 shap-0.41.0 slicer-0.0.7\n",
    "Note: you may need to restart the kernel to use updated packages."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
