{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4044d5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set(font_scale=2.2)\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import StratifiedGroupKFold, train_test_split, ShuffleSplit\n",
    "from sklearn.metrics import f1_score\n",
    "import itertools\n",
    "import lightgbm as lbg\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "import shap\n",
    "from tqdm import tqdm\n",
    "import featuretools as ft\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890f224c",
   "metadata": {},
   "source": [
    "# 1. Check Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80df108f",
   "metadata": {},
   "source": [
    "## 1.1 Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cb8d9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../input/train.csv');\n",
    "df_test = pd.read_csv('../input/test.csv');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44e9870f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train shape :  (9557, 143)   df_test shape : (23856, 142)\n"
     ]
    }
   ],
   "source": [
    "print('df_train shape : ', df_train.shape, ' ', 'df_test shape :', df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "281088bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>v2a1</th>\n",
       "      <th>hacdor</th>\n",
       "      <th>rooms</th>\n",
       "      <th>hacapo</th>\n",
       "      <th>v14a</th>\n",
       "      <th>refrig</th>\n",
       "      <th>v18q</th>\n",
       "      <th>v18q1</th>\n",
       "      <th>r4h1</th>\n",
       "      <th>...</th>\n",
       "      <th>SQBescolari</th>\n",
       "      <th>SQBage</th>\n",
       "      <th>SQBhogar_total</th>\n",
       "      <th>SQBedjefe</th>\n",
       "      <th>SQBhogar_nin</th>\n",
       "      <th>SQBovercrowding</th>\n",
       "      <th>SQBdependency</th>\n",
       "      <th>SQBmeaned</th>\n",
       "      <th>agesq</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_279628684</td>\n",
       "      <td>190000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>1849</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1849</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_f29eb3ddd</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>144</td>\n",
       "      <td>4489</td>\n",
       "      <td>1</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>64.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>4489</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_68de51c94</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>121</td>\n",
       "      <td>8464</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>64.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>8464</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_d671db89c</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>81</td>\n",
       "      <td>289</td>\n",
       "      <td>16</td>\n",
       "      <td>121</td>\n",
       "      <td>4</td>\n",
       "      <td>1.777778</td>\n",
       "      <td>1.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>289</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_d56d6f5f5</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>121</td>\n",
       "      <td>1369</td>\n",
       "      <td>16</td>\n",
       "      <td>121</td>\n",
       "      <td>4</td>\n",
       "      <td>1.777778</td>\n",
       "      <td>1.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>1369</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 143 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Id      v2a1  hacdor  rooms  hacapo  v14a  refrig  v18q  v18q1  \\\n",
       "0  ID_279628684  190000.0       0      3       0     1       1     0    NaN   \n",
       "1  ID_f29eb3ddd  135000.0       0      4       0     1       1     1    1.0   \n",
       "2  ID_68de51c94       NaN       0      8       0     1       1     0    NaN   \n",
       "3  ID_d671db89c  180000.0       0      5       0     1       1     1    1.0   \n",
       "4  ID_d56d6f5f5  180000.0       0      5       0     1       1     1    1.0   \n",
       "\n",
       "   r4h1  ...  SQBescolari  SQBage  SQBhogar_total  SQBedjefe  SQBhogar_nin  \\\n",
       "0     0  ...          100    1849               1        100             0   \n",
       "1     0  ...          144    4489               1        144             0   \n",
       "2     0  ...          121    8464               1          0             0   \n",
       "3     0  ...           81     289              16        121             4   \n",
       "4     0  ...          121    1369              16        121             4   \n",
       "\n",
       "   SQBovercrowding  SQBdependency  SQBmeaned  agesq  Target  \n",
       "0         1.000000            0.0      100.0   1849       4  \n",
       "1         1.000000           64.0      144.0   4489       4  \n",
       "2         0.250000           64.0      121.0   8464       4  \n",
       "3         1.777778            1.0      121.0    289       4  \n",
       "4         1.777778            1.0      121.0   1369       4  \n",
       "\n",
       "[5 rows x 143 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc71909a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61f9320",
   "metadata": {},
   "source": [
    "## 1.2 Make description df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba57f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "description = [\n",
    "(\"v2a1\",\" Monthly rent payment\"),\n",
    "(\"hacdor\",\" =1 Overcrowding by bedrooms\"),\n",
    "(\"rooms\",\"  number of all rooms in the house\"z),\n",
    "(\"hacapo\",\" =1 Overcrowding by rooms\"),\n",
    "(\"v14a\",\" =1 has toilet in the household\"),\n",
    "(\"refrig\",\" =1 if the household has refrigerator\"),\n",
    "(\"v18q\",\" owns a tablet\"),\n",
    "(\"v18q1\",\" number of tablets household owns\"),\n",
    "(\"r4h1\",\" Males younger than 12 years of age\"),\n",
    "(\"r4h2\",\" Males 12 years of age and older\"),\n",
    "(\"r4h3\",\" Total males in the household\"),\n",
    "(\"r4m1\",\" Females younger than 12 years of age\"),\n",
    "(\"r4m2\",\" Females 12 years of age and older\"),\n",
    "(\"r4m3\",\" Total females in the household\"),\n",
    "(\"r4t1\",\" persons younger than 12 years of age\"),\n",
    "(\"r4t2\",\" persons 12 years of age and older\"),\n",
    "(\"r4t3\",\" Total persons in the household\"),\n",
    "(\"tamhog\",\" size of the household\"),\n",
    "(\"tamviv\",\" number of persons living in the household\"),\n",
    "(\"escolari\",\" years of schooling\"),\n",
    "(\"rez_esc\",\" Years behind in school\"),\n",
    "(\"hhsize\",\" household size\"),\n",
    "(\"paredblolad\",\" =1 if predominant material on the outside wall is block or brick\"),\n",
    "(\"paredzocalo\",\" =1 if predominant material on the outside wall is socket (wood, zinc or absbesto\"),\n",
    "(\"paredpreb\",\" =1 if predominant material on the outside wall is prefabricated or cement\"),\n",
    "(\"pareddes\",\" =1 if predominant material on the outside wall is waste material\"),\n",
    "(\"paredmad\",\" =1 if predominant material on the outside wall is wood\"),\n",
    "(\"paredzinc\",\" =1 if predominant material on the outside wall is zink\"),\n",
    "(\"paredfibras\",\" =1 if predominant material on the outside wall is natural fibers\"),\n",
    "(\"paredother\",\" =1 if predominant material on the outside wall is other\"),\n",
    "(\"pisomoscer\",\" =1 if predominant material on the floor is mosaic ceramic   terrazo\"),\n",
    "(\"pisocemento\",\" =1 if predominant material on the floor is cement\"),\n",
    "(\"pisoother\",\" =1 if predominant material on the floor is other\"),\n",
    "(\"pisonatur\",\" =1 if predominant material on the floor is  natural material\"),\n",
    "(\"pisonotiene\",\" =1 if no floor at the household\"),\n",
    "(\"pisomadera\",\" =1 if predominant material on the floor is wood\"),\n",
    "(\"techozinc\",\" =1 if predominant material on the roof is metal foil or zink\"),\n",
    "(\"techoentrepiso\",\" =1 if predominant material on the roof is fiber cement,   mezzanine \"),\n",
    "(\"techocane\",\" =1 if predominant material on the roof is natural fibers\"),\n",
    "(\"techootro\",\" =1 if predominant material on the roof is other\"),\n",
    "(\"cielorazo\",\" =1 if the house has ceiling\"),\n",
    "(\"abastaguadentro\",\" =1 if water provision inside the dwelling\"),\n",
    "(\"abastaguafuera\",\" =1 if water provision outside the dwelling\"),\n",
    "(\"abastaguano\",\" =1 if no water provision\"),\n",
    "(\"public\",\" =1 electricity from CNFL,  ICE, ESPH/JASEC\"),\n",
    "(\"planpri\",\" =1 electricity from private plant\"),\n",
    "(\"noelec\",\" =1 no electricity in the dwelling\"),\n",
    "(\"coopele\",\" =1 electricity from cooperative\"),\n",
    "(\"sanitario1\",\" =1 no toilet in the dwelling\"),\n",
    "(\"sanitario2\",\" =1 toilet connected to sewer or cesspool\"),\n",
    "(\"sanitario3\",\" =1 toilet connected to  septic tank\"),\n",
    "(\"sanitario5\",\" =1 toilet connected to black hole or letrine\"),\n",
    "(\"sanitario6\",\" =1 toilet connected to other system\"),\n",
    "(\"energcocinar1\",\" =1 no main source of energy used for cooking (no kitchen)\"),\n",
    "(\"energcocinar2\",\" =1 main source of energy used for cooking electricity\"),\n",
    "(\"energcocinar3\",\" =1 main source of energy used for cooking gas\"),\n",
    "(\"energcocinar4\",\" =1 main source of energy used for cooking wood charcoal\"),\n",
    "(\"elimbasu1\",\" =1 if rubbish disposal mainly by tanker truck\"),\n",
    "(\"elimbasu2\",\" =1 if rubbish disposal mainly by botan hollow or buried\"),\n",
    "(\"elimbasu3\",\" =1 if rubbish disposal mainly by burning\"),\n",
    "(\"elimbasu4\",\" =1 if rubbish disposal mainly by throwing in an unoccupied space\"),\n",
    "(\"elimbasu5\",\" =1 if rubbish disposal mainly by throwing in river,   creek or sea\"),\n",
    "(\"elimbasu6\",\" =1 if rubbish disposal mainly other\"),\n",
    "(\"epared1\",\" =1 if walls are bad\"),\n",
    "(\"epared2\",\" =1 if walls are regular\"),\n",
    "(\"epared3\",\" =1 if walls are good\"),\n",
    "(\"etecho1\",\" =1 if roof are bad\"),\n",
    "(\"etecho2\",\" =1 if roof are regular\"),\n",
    "(\"etecho3\",\" =1 if roof are good\"),\n",
    "(\"eviv1\",\" =1 if floor are bad\"),\n",
    "(\"eviv2\",\" =1 if floor are regular\"),\n",
    "(\"eviv3\",\" =1 if floor are good\"),\n",
    "(\"dis\",\" =1 if disable person\"),\n",
    "(\"male\",\" =1 if male\"),\n",
    "(\"female\",\" =1 if female\"),\n",
    "(\"estadocivil1\",\" =1 if less than 10 years old\"),\n",
    "(\"estadocivil2\",\" =1 if free or coupled uunion\"),\n",
    "(\"estadocivil3\",\" =1 if married\"),\n",
    "(\"estadocivil4\",\" =1 if divorced\"),\n",
    "(\"estadocivil5\",\" =1 if separated\"),\n",
    "(\"estadocivil6\",\" =1 if widow/er\"),\n",
    "(\"estadocivil7\",\" =1 if single\"),\n",
    "(\"parentesco1\",\" =1 if household head\"),\n",
    "(\"parentesco2\",\" =1 if spouse/partner\"),\n",
    "(\"parentesco3\",\" =1 if son/doughter\"),\n",
    "(\"parentesco4\",\" =1 if stepson/doughter\"),\n",
    "(\"parentesco5\",\" =1 if son/doughter in law\"),\n",
    "(\"parentesco6\",\" =1 if grandson/doughter\"),\n",
    "(\"parentesco7\",\" =1 if mother/father\"),\n",
    "(\"parentesco8\",\" =1 if father/mother in law\"),\n",
    "(\"parentesco9\",\" =1 if brother/sister\"),\n",
    "(\"parentesco10\",\" =1 if brother/sister in law\"),\n",
    "(\"parentesco11\",\" =1 if other family member\"),\n",
    "(\"parentesco12\",\" =1 if other non family member\"),\n",
    "(\"idhogar\",\" Household level identifier\"),\n",
    "(\"hogar_nin\",\" Number of children 0 to 19 in household\"),\n",
    "(\"hogar_adul\",\" Number of adults in household\"),\n",
    "(\"hogar_mayor\",\" # of individuals 65+ in the household\"),\n",
    "(\"hogar_total\",\" # of total individuals in the household\"),\n",
    "(\"dependency\",\" Dependency rate\"),\n",
    "(\"edjefe\",\" years of education of male head of household\"),\n",
    "(\"edjefa\",\" years of education of female head of household\"),\n",
    "(\"meaneduc\",\"average years of education for adults (18+)\"),\n",
    "(\"instlevel1\",\" =1 no level of education\"),\n",
    "(\"instlevel2\",\" =1 incomplete primary\"),\n",
    "(\"instlevel3\",\" =1 complete primary\"),\n",
    "(\"instlevel4\",\" =1 incomplete academic secondary level\"),\n",
    "(\"instlevel5\",\" =1 complete academic secondary level\"),\n",
    "(\"instlevel6\",\" =1 incomplete technical secondary level\"),\n",
    "(\"instlevel7\",\" =1 complete technical secondary level\"),\n",
    "(\"instlevel8\",\" =1 undergraduate and higher education\"),\n",
    "(\"instlevel9\",\" =1 postgraduate higher education\"),\n",
    "(\"bedrooms\",\" number of bedrooms\"),\n",
    "(\"overcrowding\",\" # persons per room\"),\n",
    "(\"tipovivi1\",\" =1 own and fully paid house\"),\n",
    "(\"tipovivi2\",\" =1 own,   paying in installments\"),\n",
    "(\"tipovivi3\",\" =1 rented\"),\n",
    "(\"tipovivi4\",\" =1 precarious\"),\n",
    "(\"tipovivi5\",\" =1 other(assigned\"),\n",
    "(\"computer\",\" =1 if the household has notebook or desktop computer,   borrowed)\"),\n",
    "(\"television\",\" =1 if the household has TV\"),\n",
    "(\"mobilephone\",\" =1 if mobile phone\"),\n",
    "(\"qmobilephone\",\" # of mobile phones\"),\n",
    "(\"lugar1\",\" =1 region Central\"),\n",
    "(\"lugar2\",\" =1 region Chorotega\"),\n",
    "(\"lugar3\",\" =1 region PacÃƒÆ’Ã‚Â­fico central\"),\n",
    "(\"lugar4\",\" =1 region Brunca\"),\n",
    "(\"lugar5\",\" =1 region Huetar AtlÃƒÆ’Ã‚Â¡ntica\"),\n",
    "(\"lugar6\",\" =1 region Huetar Norte\"),\n",
    "(\"area1\",\" =1 zona urbana\"),\n",
    "(\"area2\",\" =2 zona rural\"),\n",
    "(\"age\",\" Age in years\"),\n",
    "(\"SQBescolari\",\" escolari squared\"),\n",
    "(\"SQBage\",\" age squared\"),\n",
    "(\"SQBhogar_total\",\" hogar_total squared\"),\n",
    "(\"SQBedjefe\",\" edjefe squared\"),\n",
    "(\"SQBhogar_nin\",\" hogar_nin squared\"),\n",
    "(\"SQBovercrowding\",\" overcrowding squared\"),\n",
    "(\"SQBdependency\",\" dependency squared\"),\n",
    "(\"SQBmeaned\",\" meaned squared\"),\n",
    "(\"agesq\",\" Age squared\"),]\n",
    "\n",
    "description = pd.DataFrame(description, columns=['varname', 'description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b77932",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_row', None)\n",
    "\n",
    "description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d2e632",
   "metadata": {},
   "source": [
    "## 1.3 Check null data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1df3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = df_train.isnull().sum().sort_values(ascending=False)\n",
    "percent = 100 * (df_train.isnull().sum() / df_train.isnull().count()).sort_values(ascending=False)\n",
    "missing_df = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "\n",
    "missing_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a347bf2b",
   "metadata": {},
   "source": [
    "## 1.4 Fill missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1bb05f7",
   "metadata": {},
   "source": [
    "* Below cell is from this kernal. https://www.kaggle.com/skooch/lgbm-w-random-split-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac046f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if education is \"yes\" and person is head of household, fill width escolari\n",
    "df_train.loc[(df_train['edjefa'] == \"yes\") & (df_train['parentesco1'] == 1), \"edjefa\"]\\\n",
    "             = df_train.loc[(df_train['edjefa'] == \"yes\") & (df_train['parentesco1'] == 1), \"escolari\"]\n",
    "df_train.loc[(df_train['edjefe'] == \"yes\") & (df_train['parentesco1'] == 1), \"edjefe\"]\\\n",
    "             = df_train.loc[(df_train['edjefe'] == \"yes\") & (df_train['parentesco1'] == 1), \"escolari\"]\n",
    "             \n",
    "df_test.loc[(df_test['edjefa'] == \"yes\") & (df_test['parentesco1'] == 1), \"edjefa\"]\\\n",
    "             = df_test.loc[(df_test['edjefa'] == \"yes\") & (df_test['parentesco1'] == 1), \"escolari\"]\n",
    "df_test.loc[(df_test['edjefe'] == \"yes\") & (df_test['parentesco1'] == 1), \"edjefe\"]\\\n",
    "             = df_test.loc[(df_test['edjefe'] == \"yes\") & (df_test['parentesco1'] == 1), \"escolari\"]\n",
    "            \n",
    "# this field is supposed to be interaction between gender and escolari, but it isn't clear what \"yes\" means, let's fill it with4\n",
    "df_train.loc[df_train['edjefa'] == \"yes\", \"edjefa\"] = 4\n",
    "df_train.loc[df_train['edjefe'] == \"yes\", \"edjefe\"] = 4\n",
    "\n",
    "df_test.loc[df_test['edjefa'] == \"yes\", \"edjefa\"] = 4\n",
    "df_test.loc[df_test['edjefe'] == \"yes\", \"edjefe\"] = 4\n",
    "\n",
    "# create feature with max education of either head of household\n",
    "df_train['edjef'] = np.max(df_train[['edjefa', 'edjefe']], axis=1)\n",
    "df_test['edjef'] = np.max(df_test[['edjefa', 'edjefe']], axis=1)\n",
    "\n",
    "# fix some inconsistencies in the data - some rows indicate both that the household does and does not have a toilet.\n",
    "# if there is no water we'll assume they do not.\n",
    "df_train.loc[(df_train.v14a == 1) & (df_train.sanitario1 == 1) & (df_train.abastaguano == 0), \"v14a\"] = 0\n",
    "df_train.loc[(df_train.v14a == 1) & (df_train.sanitario1 == 1) & (df_train.abastaguano == 0), \"sanitario1\"] = 0\n",
    "\n",
    "df_test.loc[(df_test.v14a == 1) & (df_test.sanitario1 == 1) & (df_test.abastaguano == 0), \"v14a\"] = 0\n",
    "df_test.loc[(df_test.v14a == 1) & (df_test.sanitario1 == 1) & (df_test.abastaguano == 0), \"sanitario1\"] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5cf748",
   "metadata": {},
   "source": [
    "**rez_esz, SQBmeaned**\n",
    "\n",
    "* rez_esc : Years behind in school -> filled with 0\n",
    "* SQBmeaned : square of the mean years of education of adults(>=18) in the household agesq, Age squared -> same with rez_esc -> filled with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5d0832",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['rez_esc'].fillna(0, inplace=True)\n",
    "df_test['rez_esc'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e2f421",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['SQBmeaned'].fillna(0, inplace=True)\n",
    "df_test['SQBmeaned'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f31ab0",
   "metadata": {},
   "source": [
    "**meaneduc**\n",
    "* meaneduc : average years of education for adults(18+) -> filled with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a940509a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['meaneduc'].fillna(0, inplace=True)\n",
    "df_test['meaneduc'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76460192",
   "metadata": {},
   "source": [
    "**v18q1**\n",
    "* v18q1 : number of tablets household owns -> if v18q(Do you own a \n",
    "tablet?) == 1, there are some values. If not, only NaN values in v18q1, See below 3 cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcb042b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['v18q'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f7ab40",
   "metadata": {},
   "source": [
    "* v18q1 : number of tablets household owns -> if v18q == 1, there are some values. if not, only NaN values there. See below two cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6f856e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[df_train['v18q'] == 1, 'v18q1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9887582",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[df_train['v18q'] == 0, 'v18q1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed31426",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['v18q1'].fillna(0, inplace=True)\n",
    "df_test['v18q1'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85211d68",
   "metadata": {},
   "source": [
    "* v2a1 : number of tablets household owns -> if tipovivi3(rented?) == 1, there are some values. if not, there are also some values.\n",
    "* NaN value could be replaced by 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37be3b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['tipovivi3'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91155955",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(df_train.loc[df_train['tipovivi3'] == 1, 'v2a1'], label='Monthly rent payment of household(rented=1)')\n",
    "sns.kdeplot(df_train.loc[df_train['tipovivi3'] == 0, 'v2a1'], label='Monthly rent payment of household(rented=0)')\n",
    "plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0c394e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['v2a1'].fillna(0, inplace=True)\n",
    "df_test['v2a1'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f337f019",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = df_train.isnull().sum().sort_values(ascending=False)\n",
    "percent = 100 * (df_train.isnull().sum() / df_train.isnull().count()).sort_values(ascending=False)\n",
    "missing_df = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "missing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be37dc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = df_test.isnull().sum().sort_values(ascending=False)\n",
    "percent = 100 * (df_test.isnull().sum() / df_test.isnull().count()).sort_values(ascending=False)\n",
    "missing_df = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "\n",
    "missing_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4297fa",
   "metadata": {},
   "source": [
    "**For now, there are no NaN values.**\n",
    "## 2. Feature engineering\n",
    "### 2.1 Object features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18384d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_object = [col for col in df_train.columns if df_train[col].dtype == 'object']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac22eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abff4f1",
   "metadata": {},
   "source": [
    "**dependency**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc21c97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some dependencies are Na, fill those with the squre root of the square.\n",
    "df_train['dependency'] = np.sqrt(df_train['SQBdependency'])\n",
    "df_test['dependency'] = np.sqrt(df_test['SQBdependency'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81219abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train['dependency'] = df_train['dependency'].replace({np.inf: 0})\n",
    "# df_test['dependency'] = df_test['dependency'].replace({np.inf: 0})\n",
    "\n",
    "# def replace_dependency(x):\n",
    "#     if x == 'yes':\n",
    "#         return 10\n",
    "#     elif x == 'no':\n",
    "#         return 0\n",
    "#     else:\n",
    "#         return x\n",
    "\n",
    "# df_train['dependency'] = df_train['dependency'].apply(replace_dependency).astype(float)\n",
    "# df_test['dependency'] = df_test['dependency'].apply(replace_dependency).astype(float)\n",
    "\n",
    "# - As you can see, setting yes -> 10 and no -> 0 is good choice.\n",
    "# - At first, fill inf value with 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124b314f",
   "metadata": {},
   "source": [
    "**edjefe**\n",
    "* edjefe, years of education of male head of household, based on the interaction of escolari(years of education), head of household and gender, yes=1 and no =0.\n",
    "* replace yes -> 1 and no -> 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c40eb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_edjefe(x):\n",
    "    if x == 'yes':\n",
    "        return 1\n",
    "    elif x == 'no':\n",
    "        return 0\n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "df_train['edjefe'] = df_train['edjefe'].apply(replace_edjefe).astype(float)\n",
    "df_test['edjefe'] = df_test['edjefe'].apply(replace_edjefe).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f752b5",
   "metadata": {},
   "source": [
    "**edjefa**\n",
    "* edjefa, years of education of female head of household, based on the interaction of escolari(years of education), head of house hold and gender, yes=1 and no=1.\n",
    "* replace yes-> 1 and no ->0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c9ff1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_edjefa(x):\n",
    "    if x == 'yes':\n",
    "        return 1\n",
    "    elif x == 'no':\n",
    "        return 0\n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "df_train['edjefa'] = df_train['edjefa'].apply(replace_edjefa).astype(float)\n",
    "df_test['edjefa'] = df_test['edjefa'].apply(replace_edjefa).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52595cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create feature with max education of either head of household.\n",
    "df_train['edjef'] = np.max(df_train[['edjefa', 'edjefe']], axis=1)\n",
    "df_test['edjef'] = np.max(df_test[['edjefa', 'edjefe']], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e720b671",
   "metadata": {},
   "source": [
    "### roof and electricity\n",
    "* I refered to https://www.kaggle.com/mineshjethva/exploratory-data-analysis-lightgbm. Thanks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fee1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['roof_waste_material'] = np.nan\n",
    "df_test['roof_waste_material'] = np.nan\n",
    "df_train['electricity_other'] = np.nan\n",
    "df_test['electricity_other'] = np.nan\n",
    "\n",
    "def fill_roof_exception(x):\n",
    "    if (x['techozinc'] == 0) and (x['techoentrepiso'] == 0) and (x['techocane'] == 0) and (x['techootro'] == 0):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def fill_no_electricity(x):\n",
    "    if (x['public'] == 0) and (x['planpri'] == 0) and (x['noelec'] == 0) and (x['coopele'] == 0):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "df_train['roof_waste_material'] = df_train.apply(lambda x : fill_roof_exception(x), axis=1)\n",
    "df_test['roof_waste_material'] = df_test.apply(lambda x : fill_roof_exception(x), axis=1)\n",
    "df_train['electricity_other'] = df_train.apply(lambda x : fill_no_electricity(x), axis=1)\n",
    "df_test['electricity_other'] = df_test.apply(lambda x : fill_no_electricity(x), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee28fa3f",
   "metadata": {},
   "source": [
    "## 2.2 Extract cat features\n",
    "* According to data scription, there are many binary categoty features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1dc6321",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_cat_features = [col for col in df_train.columns if df_train[col].value_counts().shape[0] == 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a436a0a5",
   "metadata": {},
   "source": [
    "## 2.3 Make new features using continuous features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea05d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_features = [col for col in df_train.columns if col not in binary_cat_features]\n",
    "continuous_features = [col for col in continuous_features if col not in features_object]\n",
    "continuous_features = [col for col in continuous_features if col not in ['Id', 'Target', 'idhogar']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5f5c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('There are {} continuous features'.format(len(continuous_features)))\n",
    "for col in continuous_features:\n",
    "    print('{}: {}'.format(col, description.loc[description['varname'] == col, 'description'].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04dc2b11",
   "metadata": {},
   "source": [
    "* hhsize : household size\n",
    "* tamhog : size of the household\n",
    "\n",
    "What is different?\n",
    "\n",
    "* As you can see, the meaning of two features are same but the exact number are different. Are they different?\n",
    "* I don't know. For now, I decided to drop one feature 'tamhog'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4e84b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['edjef'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec82bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop('tamhog', axis=1, inplace=True)\n",
    "df_test.drop('tamhog', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e3245c",
   "metadata": {},
   "source": [
    "### Squared features\n",
    "* There are many squared features. Actually, tree models like lightgbm don't need them. But at this kernel, I want to use lightgbm as feature filter model and set entity- embedding as classfier. So Let's keep them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7a33e1",
   "metadata": {},
   "source": [
    "### Family features\n",
    "* hogar_nin, hogar_adul, hogar_mayor, hogar_total, r4h1, r4h2, r4h3, r4m1, r4m2, r4m3, r4t1, r4t2, r4t3, tmbhog, tamvid, rez_esc, escolari"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b53d08d",
   "metadata": {},
   "source": [
    "* Family size features (substract, ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a29cbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['adult'] = df_train['hogar_adul'] - df_train['hogar_mayor']\n",
    "df_train['dependency_count'] = df_train['hogar_nin'] + df_train['hogar_mayor']\n",
    "df_train['dependency'] = df_train['dependency_count'] / df_train['adult']\n",
    "df_train['child_percent'] = df_train['hogar_nin'] / df_train['hogar_total']\n",
    "df_train['elder_percent'] = df_train['hogar_mayor'] / df_train['hogar_total']\n",
    "df_train['adult_percent'] = df_train['hogar_adul'] / df_train['hogar_total']\n",
    "df_train['males_younger_12_years_percent'] = df_train['r4h1'] / df_train['hogar_total']\n",
    "df_train['males_older_12_years_percent'] = df_train['r4h2'] / df_train['hogar_total']\n",
    "df_train['males_percent'] = df_train['r4h3'] / df_train['hogar_total']\n",
    "df_train['females_younger_12_years_percent'] = df_train['r4m1'] / df_train['hogar_total']\n",
    "df_train['females_older_12_years_percent'] = df_train['r4m2'] / df_train['hogar_total']\n",
    "df_train['females_percent'] = df_train['r4m3'] / df_train['hogar_total']\n",
    "df_train['persons_younger_12_years_percent'] = df_train['r4t1'] / df_train['hogar_total']\n",
    "df_train['persons_older_12_years_percent'] = df_train['r4t2'] / df_train['hogar_total']\n",
    "df_train['persons_percent'] = df_train['r4t3'] / df_train['hogar_total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd3fb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['adult'] = df_test['hogar_adul'] - df_test['hogar_mayor']\n",
    "df_test['dependency_count'] = df_test['hogar_nin'] + df_test['hogar_mayor']\n",
    "df_test['dependency'] = df_test['dependency_count'] / df_test['adult']\n",
    "df_test['child_percent'] = df_test['hogar_nin'] / df_test['hogar_total']\n",
    "df_test['elder_percent'] = df_test['hogar_mayor'] / df_test['hogar_total']\n",
    "df_test['adult_percent'] = df_test['hogar_adul'] / df_test['hogar_total']\n",
    "df_test['males_younger_12_years_percent'] = df_test['r4h1'] / df_test['hogar_total']\n",
    "df_test['males_older_12_years_percent'] = df_test['r4h2'] / df_test['hogar_total']\n",
    "df_test['males_percent'] = df_test['r4h3'] / df_test['hogar_total']\n",
    "df_test['females_younger_12_years_percent'] = df_test['r4m1'] / df_test['hogar_total']\n",
    "df_test['females_older_12_years_percent'] = df_test['r4m2'] / df_test['hogar_total']\n",
    "df_test['females_percent'] = df_test['r4m3'] / df_test['hogar_total']\n",
    "df_test['persons_younger_12_years_percent'] = df_test['r4t1'] / df_test['hogar_total']\n",
    "df_test['persons_older_12_years_percent'] = df_test['r4t2'] / df_test['hogar_total']\n",
    "df_test['persons_percent'] = df_test['r4t3'] / df_test['hogar_total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386f32c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['males_younger_12_years_in_household_size'] = df_train['r4h1'] / df_train['hhsize']\n",
    "df_train['males_older_12_years_in_household_size'] = df_train['r4h2'] / df_train['hhsize']\n",
    "df_train['males_in_household_size'] = df_train['r4h3'] / df_train['hhsize']\n",
    "df_train['females_younger_12_years_in_household_size'] = df_train['r4m1'] / df_train['hhsize']\n",
    "df_train['females_older_12_years_in_household_size'] = df_train['r4m2'] / df_train['hhsize']\n",
    "df_train['females_in_household_size'] = df_train['r4m3'] / df_train['hogar_total']\n",
    "df_train['persons_younger_12_years_in_household_size'] = df_train['r4t1'] / df_train['hhsize']\n",
    "df_train['persons_older_12_years_in_household_size'] = df_train['r4t2'] / df_train['hhsize']\n",
    "df_train['persons_in_household_size'] = df_train['r4t3'] / df_train['hhsize']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37552b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['males_younger_12_years_in_household_size'] = df_test['r4h1'] / df_test['hhsize']\n",
    "df_test['males_older_12_years_in_household_size'] = df_test['r4h2'] / df_test['hhsize']\n",
    "df_test['males_in_household_size'] = df_test['r4h3'] / df_test['hhsize']\n",
    "df_test['females_younger_12_years_in_household_size'] = df_test['r4m1'] / df_test['hhsize']\n",
    "df_test['females_older_12_years_in_household_size'] = df_test['r4m2'] / df_test['hhsize']\n",
    "df_test['females_in_household_size'] = df_test['r4m3'] / df_test['hogar_total']\n",
    "df_test['persons_younger_12_years_in_household_size'] = df_test['r4t1'] / df_test['hhsize']\n",
    "df_test['persons_older_12_years_in_household_size'] = df_test['r4t2'] / df_test['hhsize']\n",
    "df_test['persons_in_household_size'] = df_test['r4t3'] / df_test['hhsize']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57aa8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['overcrowding_room_and_bedroom'] = (df_train['hacdor'] + df_train['hacapo'])/2\n",
    "df_test['overcrowding_room_and_bedroom'] = (df_test['hacdor'] + df_test['hacapo'])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299f34e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['escolari_age'] = df_train['escolari']/df_train['age']\n",
    "df_test['escolari_age'] = df_test['escolari']/df_test['age']\n",
    "\n",
    "df_train['age_12_19'] = df_train['hogar_nin'] - df_train['r4t1']\n",
    "df_test['age_12_19'] = df_test['hogar_nin'] - df_test['r4t1']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae860be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['phones-per-capita'] = df_train['qmobilephone'] / df_train['tamviv']\n",
    "df_train['tablets-per-capita'] = df_train['v18q1'] / df_train['tamviv']\n",
    "df_train['rooms-per-capita'] = df_train['rooms'] / df_train['tamviv']\n",
    "df_train['rent-per-capita'] = df_train['v2a1'] / df_train['tamviv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c90a4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['phones-per-capita'] = df_test['qmobilephone'] / df_test['tamviv']\n",
    "df_test['tablets-per-capita'] = df_test['v18q1'] / df_test['tamviv']\n",
    "df_test['rooms-per-capita'] = df_test['rooms'] / df_test['tamviv']\n",
    "df_test['rent-per-capita'] = df_test['v2a1'] / df_test['tamviv']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2673efc9",
   "metadata": {},
   "source": [
    "* You can see that \"Total persons in the household\" != \"# of total individuals in the household\".\n",
    "* Somewhat weired. But for now I will keep it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76834f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_train['hogar_total'] == df_train['r4t3']).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a012c59e",
   "metadata": {},
   "source": [
    "### Rent per family features\n",
    "\n",
    "* I will reduce the number of features using shap, so let's generate many features!! Hope catch some fortune features :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038db9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "family_size_features = ['adult', 'hogar_adul', 'hogar_mayor', 'hogar_nin', 'hogar_total', 'r4h1', \n",
    "                        'r4h2', 'r4h3', 'r4m1', 'r4m2', 'r4m3', 'r4t1', 'r4t2', 'r4t3', 'hhsize']\n",
    "new_feats = []\n",
    "for col in family_size_features:\n",
    "    new_col_name = 'new_{}_per_{}'.format('v2a1', col)\n",
    "    new_feats.append(new_col_name)\n",
    "    df_train[new_col_name] = df_train['v2a1'] / df_train[col]\n",
    "    df_test[new_col_name] = df_test['v2a1'] / df_test[col]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31b2545",
   "metadata": {},
   "source": [
    "* Ratio feature can have infinite values. So Let them be filled with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40dd6e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in new_feats:\n",
    "    df_train[col].replace([np.inf], np.nan, inplace=True)\n",
    "    df_train[col].fillna(0, inplace=True)\n",
    "    \n",
    "    df_test[col].replace([np.inf], np.nan, inplace=True)\n",
    "    df_test[col].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7f1eb1",
   "metadata": {},
   "source": [
    "### Room per family features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21ea01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feats = []\n",
    "for col in family_size_features:\n",
    "    new_col_name = 'new_{}_per_{}'.format('rooms', col)\n",
    "    new_feats.append(new_col_name)\n",
    "    df_train[new_col_name] = df_train['rooms'] / df_train[col]\n",
    "    df_test[new_col_name] = df_test['rooms'] / df_test[col]\n",
    "\n",
    "for col in new_feats:\n",
    "    df_train[col].replace([np.inf], np.nan, inplace=True)\n",
    "    df_train[col].fillna(0, inplace=True)\n",
    "    \n",
    "    df_test[col].replace([np.inf], np.nan, inplace=True)\n",
    "    df_test[col].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481f6574",
   "metadata": {},
   "source": [
    "### BedRoom per family features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2569287",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feats = []\n",
    "for col in family_size_features:\n",
    "    new_col_name = 'new_{}_per_{}'.format('bedrooms', col)\n",
    "    new_feats.append(new_col_name)\n",
    "    df_train[new_col_name] = df_train['bedrooms'] / df_train[col]\n",
    "    df_test[new_col_name] = df_test['bedrooms'] / df_test[col]\n",
    "\n",
    "for col in new_feats:\n",
    "    df_train[col].replace([np.inf], np.nan, inplace=True)\n",
    "    df_train[col].fillna(0, inplace=True)\n",
    "    \n",
    "    df_test[col].replace([np.inf], np.nan, inplace=True)\n",
    "    df_test[col].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24807cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train.shape, df_test.shape) # To check the same number of features between train and test (target is there in train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f430416f",
   "metadata": {},
   "source": [
    "### Tabulet per family features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56383c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feats = []\n",
    "for col in family_size_features:\n",
    "    new_col_name = 'new_{}_per_{}'.format('v18q1', col)\n",
    "    new_feats.append(new_col_name)\n",
    "    df_train[new_col_name] = df_train['v18q1'] / df_train[col]\n",
    "    df_test[new_col_name] = df_test['v18q1'] / df_test[col]\n",
    "\n",
    "for col in new_feats:\n",
    "    df_train[col].replace([np.inf], np.nan, inplace=True)\n",
    "    df_train[col].fillna(0, inplace=True)\n",
    "    \n",
    "    df_test[col].replace([np.inf], np.nan, inplace=True)\n",
    "    df_test[col].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73972390",
   "metadata": {},
   "source": [
    "### phone per family features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029bf2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feats = []\n",
    "for col in family_size_features:\n",
    "    new_col_name = 'new_{}_per_{}'.format('qmobilephone', col)\n",
    "    new_feats.append(new_col_name)\n",
    "    df_train[new_col_name] = df_train['qmobilephone'] / df_train[col]\n",
    "    df_test[new_col_name] = df_test['qmobilephone'] / df_test[col]\n",
    "\n",
    "for col in new_feats:\n",
    "    df_train[col].replace([np.inf], np.nan, inplace=True)\n",
    "    df_train[col].fillna(0, inplace=True)\n",
    "    \n",
    "    df_test[col].replace([np.inf], np.nan, inplace=True)\n",
    "    df_test[col].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49d154e",
   "metadata": {},
   "source": [
    "### rez_esc(Years behind in school) per family features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d4e151",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feats = []\n",
    "for col in family_size_features:\n",
    "    new_col_name = 'new_{}_per_{}'.format('rez_esc', col)\n",
    "    new_feats.append(new_col_name)\n",
    "    df_train[new_col_name] = df_train['rez_esc'] / df_train[col]\n",
    "    df_test[new_col_name] = df_test['rez_esc'] / df_test[col]\n",
    "\n",
    "for col in new_feats:\n",
    "    df_train[col].replace([np.inf], np.nan, inplace=True)\n",
    "    df_train[col].fillna(0, inplace=True)\n",
    "    \n",
    "    df_test[col].replace([np.inf], np.nan, inplace=True)\n",
    "    df_test[col].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b448171e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['rez_esc_age'] = df_train['rez_esc'] / df_train['age']\n",
    "df_train['rez_esc_escolari'] = df_train['rez_esc'] / df_train['escolari']\n",
    "\n",
    "df_test['rez_esc_age'] = df_test['rez_esc'] / df_test['age']\n",
    "df_test['rez_esc_escolari'] = df_test['rez_esc'] / df_test['escolari']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147b809e",
   "metadata": {},
   "source": [
    "### Rich features\n",
    "* I think the more richer, the larger number of phones and tabulet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706c6ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['tabulet_x_qmobilephone'] = df_train['v18q1'] * df_train['qmobilephone']\n",
    "df_test['tabulet_x_qmobilephone'] = df_test['v18q1'] * df_test['qmobilephone']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edcd6e2",
   "metadata": {},
   "source": [
    "* wall, roof, floor may be key factor.\n",
    "* Let's multiply each of them. Becuase they are binary cat features, so mulitification of each features generates new categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2733a7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wall and roof\n",
    "for col1 in ['epared1', 'epared2', 'epared3']:\n",
    "    for col2 in ['etecho1', 'etecho2', 'etecho3']:\n",
    "        new_col_name = 'new_{}_x_{}'.format(col1, col2)\n",
    "        df_train[new_col_name] = df_train[col1] * df_train[col2]\n",
    "        df_test[new_col_name] = df_test[col1] * df_test[col2]\n",
    "        \n",
    "# wall and floor\n",
    "for col1 in ['epared1', 'epared2', 'epared3']:\n",
    "    for col2 in ['eviv1', 'eviv2', 'eviv3']:\n",
    "        new_col_name = 'new_{}_x_{}'.format(col1, col2)\n",
    "        df_train[new_col_name] = df_train[col1] * df_train[col2]\n",
    "        df_test[new_col_name] = df_test[col1] * df_test[col2]\n",
    "\n",
    "# roof and floor\n",
    "for col1 in ['etecho1', 'etecho2', 'etecho3']:\n",
    "    for col2 in ['eviv1', 'eviv2', 'eviv3']:\n",
    "        new_col_name = 'new_{}_x_{}'.format(col1, col2)\n",
    "        df_train[new_col_name] = df_train[col1] * df_train[col2]\n",
    "        df_test[new_col_name] = df_test[col1] * df_test[col2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c445ca",
   "metadata": {},
   "source": [
    "* combination using three features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1f5bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col1 in ['epared1', 'epared2', 'epared3']:\n",
    "    for col2 in ['etecho1', 'etecho2', 'etecho3']:\n",
    "        for col3 in ['eviv1', 'eviv2', 'eviv3']:\n",
    "            new_col_name = 'new_{}_x_{}_x_{}'.format(col1, col2, col3)\n",
    "            df_train[new_col_name] = df_train[col1] * df_train[col2] * df_train[col3]\n",
    "            df_test[new_col_name] = df_test[col1] * df_test[col2] * df_train[col3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c4e79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36af8026",
   "metadata": {},
   "source": [
    "* I want to mix electricity and energy features -> energy features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55c1c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col1 in ['public', 'planpri', 'noelec', 'coopele']:\n",
    "    for col2 in ['energcocinar1', 'energcocinar2', 'energcocinar3', 'energcocinar4']:\n",
    "        new_col_name = 'new_{}_x_{}'.format(col1, col2)\n",
    "        df_train[new_col_name] = df_train[col1] * df_train[col2]\n",
    "        df_test[new_col_name] = df_test[col1] * df_test[col2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5c03b1",
   "metadata": {},
   "source": [
    "* I want to mix toilet and rubbish disposal features -> other_infra features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1d5ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col1 in ['sanitario1', 'sanitario2', 'sanitario3', 'sanitario5', 'sanitario6']:\n",
    "    for col2 in ['elimbasu1', 'elimbasu2', 'elimbasu3', 'elimbasu4', 'elimbasu5', 'elimbasu6']:\n",
    "        new_col_name = 'new_{}_x_{}'.format(col1, col2)\n",
    "        df_train[new_col_name] = df_train[col1] * df_train[col2]\n",
    "        df_test[new_col_name] = df_test[col1] * df_test[col2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3068272",
   "metadata": {},
   "source": [
    "* I want to mix toilet and water provision features -> water features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd959f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col1 in ['abastaguadentro', 'abastaguafuera', 'abastaguano']:\n",
    "    for col2 in ['sanitario1', 'sanitario2', 'sanitario3', 'sanitario5', 'sanitario6']:\n",
    "        new_col_name = 'new_{}_x_{}'.format(col1, col2)\n",
    "        df_train[new_col_name] = df_train[col1] * df_train[col2]\n",
    "        df_test[new_col_name] = df_test[col1] * df_test[col2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26548d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ee20f1",
   "metadata": {},
   "source": [
    "* I want mix education and area features -> education_zone_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3e74e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col1 in ['area1', 'area2']:\n",
    "    for col2 in ['instlevel1', 'instlevel2', 'instlevel3', 'instlevel4', 'instlevel5', 'instlevel6', 'instlevel7', 'instlevel8', 'instlevel9']:\n",
    "        new_col_name = 'new_{}_x_{}'.format(col1, col2)\n",
    "        df_train[new_col_name] = df_train[col1] * df_train[col2]\n",
    "        df_test[new_col_name] = df_test[col1] * df_test[col2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5b08c7",
   "metadata": {},
   "source": [
    "* Mix region and education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c12384",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col1 in ['lugar1', 'lugar2', 'lugar3', 'lugar4', 'lugar5', 'lugar6']:\n",
    "    for col2 in ['instlevel1', 'instlevel2', 'instlevel3', 'instlevel4', 'instlevel5', 'instlevel6', 'instlevel7', 'instlevel8', 'instlevel9']:\n",
    "        new_col_name = 'new_{}_x_{}'.format(col1, col2)\n",
    "        df_train[new_col_name] = df_train[col1] * df_train[col2]\n",
    "        df_test[new_col_name] = df_test[col1] * df_test[col2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e727c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96570302",
   "metadata": {},
   "source": [
    "* Multiply television / mobilephone / computer / tabulet / refrigerator -> electornics features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f820340",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['electronics'] = df_train['computer'] * df_train['mobilephone'] * df_train['television'] * df_train['v18q'] * df_train['refrig']\n",
    "df_test['electronics'] = df_test['computer'] * df_test['mobilephone'] * df_test['television'] * df_test['v18q'] * df_test['refrig']\n",
    "\n",
    "df_train['no_appliances'] = df_train['refrig'] + df_train['computer'] + df_train['television'] + df_train['mobilephone']\n",
    "df_test['no_appliances'] = df_test['refrig'] + df_test['computer'] + df_test['television'] + df_test['mobilephone']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ecb254",
   "metadata": {},
   "source": [
    "* Mix wall material of roof, floor, wall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc35b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col1 in ['paredblolad', 'paredzocalo', 'paredpreb', 'pareddes', 'paredmad', 'paredzinc', 'paredfibras', 'paredother']:\n",
    "    for col2 in ['pisomoscer', 'pisocemento', 'pisoother', 'pisonatur', 'pisonotiene', 'pisomadera']:\n",
    "        new_col_name = 'new_{}_x_{}'.format(col1, col2)\n",
    "        df_train[new_col_name] = df_train[col1] * df_train[col2]\n",
    "        df_test[new_col_name] = df_test[col1] * df_test[col2]\n",
    "\n",
    "for col1 in ['pisomoscer', 'pisocemento', 'pisoother', 'pisonatur', 'pisonotiene', 'pisomadera']:\n",
    "    for col1 in ['techozinc', 'techoentrepiso', 'techocane', 'techootro']:\n",
    "        new_col_name = 'new_{}_x_{}'.format(col1, col2)\n",
    "        df_train[new_col_name] = df_train[col1] * df_train[col2]\n",
    "        df_test[new_col_name] = df_test[col1] * df_test[col2]\n",
    "        \n",
    "for col1 in ['paredblolad', 'paredzocalo', 'paredpreb', 'pareddes', 'paredmad', 'paredzinc', 'paredfibras', 'paredother']:\n",
    "    for col2 in ['techozinc', 'techoentrepiso', 'techocane', 'techootro']:\n",
    "        new_col_name = 'new_{}_x_{}'.format(col1, col2)\n",
    "        df_train[new_col_name] = df_train[col1] * df_train[col2]\n",
    "        df_test[new_col_name] = df_test[col1] * df_test[col2]        \n",
    "        \n",
    "for col1 in ['paredblolad', 'paredzocalo', 'paredpreb', 'pareddes', 'paredmad', 'paredzinc', 'paredfibras', 'paredother']:\n",
    "    for col2 in ['pisomoscer', 'pisocemento', 'pisoother', 'pisonatur', 'pisonotiene', 'pisomadera']:\n",
    "        for col3 in ['techozinc', 'techoentrepiso', 'techocane', 'techootro']:\n",
    "            new_col_name = 'new_{}_x_{}_x_{}'.format(col1, col2, col3)\n",
    "            df_train[new_col_name] = df_train[col1] * df_train[col2] * df_train[col3]\n",
    "            df_test[new_col_name] = df_test[col1] * df_test[col2] * df_train[col3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181bc8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7aed3a",
   "metadata": {},
   "source": [
    "* Wow! without any aggreation features, we hvae 446 features for now. Actually mixing the materials of walls make thousands of features. I don't want to do that because of computational costs!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94ebe09",
   "metadata": {},
   "source": [
    "### Remove feature with only one value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0daded6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_with_only_one_value = []\n",
    "for col in df_train.columns:\n",
    "    if col == 'Target':\n",
    "        continue\n",
    "    if df_train[col].value_counts().shape[0] == 1 or df_test[col].value_counts().shape[0] == 1:\n",
    "        print(col)\n",
    "        cols_with_only_one_value.append(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4c38c6",
   "metadata": {},
   "source": [
    "* Let's remove them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383f84ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop(cols_with_only_one_value, axis=1, inplace=True)\n",
    "df_test.drop(cols_with_only_one_value, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2552755",
   "metadata": {},
   "source": [
    "### Check whether both train and test have same features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09d15dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_train = np.array(sorted([col for col in df_train.columns if col != 'Target']))\n",
    "cols_test = np.array(sorted(df_test.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85a17fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "(cols_train == cols_test).sum() == len(cols_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7735d551",
   "metadata": {},
   "source": [
    "* Good, Let's move!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f84f840",
   "metadata": {},
   "source": [
    "## 2.4 aggregation features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b713ed80",
   "metadata": {},
   "source": [
    "* In this competition, each samples are member of spectific household(idhogar). So let's aggregate based on 'idhogar' values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a6e38f",
   "metadata": {},
   "source": [
    "### Aggregation for family features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24baf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_min(x):\n",
    "    return x.max() - x.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a987aa37",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_train = pd.DataFrame()\n",
    "agg_test = pd.DataFrame()\n",
    "\n",
    "for item in tqdm(family_size_features):\n",
    "    for i, function in enumerate(['mean','std','min','max','sum', 'count', max_min]):\n",
    "        group_train = df_train[item].groupby(df_train['idhogar']).agg(function)\n",
    "        group_test = df_test[item].groupby(df_test['idhogar']).agg(function)\n",
    "        if i == 6:\n",
    "            new_col = item + '_new_' + 'max_min'\n",
    "        else:\n",
    "            new_col = item + '_new_' + function\n",
    "        agg_train[new_col] = group_train\n",
    "        agg_test[new_col] = group_test\n",
    "\n",
    "print('new aggregate train set has {} rows, and {} features'.format(agg_train.shape[0], agg_train.shape[1]))\n",
    "print('new aggregate test set has {} rows, and {} features'.format(agg_test.shape[0], agg_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe87d019",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggr_list = ['rez_esc', 'dis', 'male', 'female', \n",
    "                  'estadocivil1', 'estadocivil2', 'estadocivil3', 'estadocivil4', 'estadocivil5', 'estadocivil6', 'estadocivil7', \n",
    "                  'parentesco2', 'parentesco3', 'parentesco4', 'parentesco5', 'parentesco6', 'parentesco7', 'parentesco8', 'parentesco9', 'parentesco10', \n",
    "                  'parentesco11', 'parentesco12',\n",
    "                  'instlevel1', 'instlevel2', 'instlevel3', 'instlevel4', 'instlevel5', 'instlevel6', 'instlevel7', 'instlevel8', 'instlevel9',\n",
    "                 'epared1', 'epared2', 'epared3', 'etecho1', 'etecho2', 'etecho3', 'eviv1', 'eviv2', 'eviv3', 'refrig', 'television', 'mobilephone',\n",
    "            'area1', 'area2', 'v18q', 'edjef']\n",
    "\n",
    "\n",
    "\n",
    "for item in tqdm(aggr_list):\n",
    "    for function in ['count', 'sum']:\n",
    "        group_train = df_train[item].groupby(df_train['idhogar']).agg(function)\n",
    "        group_test = df_test[item].groupby(df_test['idhogar']).agg(function)\n",
    "        new_col = item + '_new1_' + function\n",
    "        agg_train[new_col] = group_train\n",
    "        agg_test[new_col] = group_test\n",
    "print('new aggregate train set has {} rows, and {} features'.format(agg_train.shape[0], agg_train.shape[1]))\n",
    "print('new aggregate test set has {} rows, and {} features'.format(agg_test.shape[0], agg_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9270cbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggr_list = ['escolari', 'age', 'escolari_age', 'dependency', 'bedrooms', 'overcrowding', 'rooms', 'qmobilephone', 'v18q1']\n",
    "\n",
    "for item in tqdm(aggr_list):\n",
    "    for function in ['mean','std','min','max','sum', 'count', max_min]:\n",
    "        group_train = df_train[item].groupby(df_train['idhogar']).agg(function)\n",
    "        group_test = df_test[item].groupby(df_test['idhogar']).agg(function)\n",
    "        if i == 6:\n",
    "            new_col = item + '_new2_' + 'max_min'\n",
    "        else:\n",
    "            new_col = item + '_new2_' + function\n",
    "        agg_train[new_col] = group_train\n",
    "        agg_test[new_col] = group_test\n",
    "\n",
    "print('new aggregate train set has {} rows, and {} features'.format(agg_train.shape[0], agg_train.shape[1]))\n",
    "print('new aggregate test set has {} rows, and {} features'.format(agg_test.shape[0], agg_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfc6b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_test = agg_test.reset_index()\n",
    "agg_train = agg_train.reset_index()\n",
    "\n",
    "train_agg = pd.merge(df_train, agg_train, on='idhogar')\n",
    "test = pd.merge(df_test, agg_test, on='idhogar')\n",
    "\n",
    "#fill all na as 0\n",
    "train_agg.fillna(value=0, inplace=True)\n",
    "test.fillna(value=0, inplace=True)\n",
    "\n",
    "print('train shape:', train_agg.shape, 'test shape:', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5521d98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggr_list = ['rez_esc', 'dis', 'male', 'female', \n",
    "                  'estadocivil1', 'estadocivil2', 'estadocivil3', 'estadocivil4', 'estadocivil5', 'estadocivil6', 'estadocivil7', \n",
    "                  'parentesco2', 'parentesco3', 'parentesco4', 'parentesco5', 'parentesco6', 'parentesco7', 'parentesco8', 'parentesco9', 'parentesco10', \n",
    "                  'parentesco11', 'parentesco12',\n",
    "                  'instlevel1', 'instlevel2', 'instlevel3', 'instlevel4', 'instlevel5', 'instlevel6', 'instlevel7', 'instlevel8', 'instlevel9',\n",
    "                 'epared1', 'epared2', 'epared3', 'etecho1', 'etecho2', 'etecho3', 'eviv1', 'eviv2', 'eviv3', 'refrig', 'television', 'mobilephone',\n",
    "            'area1', 'area2', 'v18q', 'edjef']\n",
    "    \n",
    "for lugar in ['lugar1', 'lugar2', 'lugar3', 'lugar4', 'lugar5', 'lugar6']:\n",
    "    group_train = df_train[[lugar, 'idhogar'] + aggr_list].groupby([lugar, 'idhogar']).sum().reset_index()\n",
    "    group_train.columns = [lugar, 'idhogar'] + ['new3_{}_idhogar_{}'.format(lugar, col) for col in group_train][2:]\n",
    "\n",
    "    group_test = df_test[[lugar, 'idhogar'] + aggr_list].groupby([lugar, 'idhogar']).sum().reset_index()\n",
    "    group_test.columns = [lugar, 'idhogar'] + ['new3_{}_idhogar_{}'.format(lugar, col) for col in group_test][2:]\n",
    "\n",
    "    train_agg = pd.merge(train_agg, group_train, on=[lugar, 'idhogar'])\n",
    "    test = pd.merge(test, group_test, on=[lugar, 'idhogar'])\n",
    "    \n",
    "print('train shape:', train_agg.shape, 'test shape:', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7915fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggr_list = ['rez_esc', 'dis', 'male', 'female', \n",
    "                  'estadocivil1', 'estadocivil2', 'estadocivil3', 'estadocivil4', 'estadocivil5', 'estadocivil6', 'estadocivil7', \n",
    "                  'parentesco2', 'parentesco3', 'parentesco4', 'parentesco5', 'parentesco6', 'parentesco7', 'parentesco8', 'parentesco9', 'parentesco10', \n",
    "                  'parentesco11', 'parentesco12',\n",
    "                  'instlevel1', 'instlevel2', 'instlevel3', 'instlevel4', 'instlevel5', 'instlevel6', 'instlevel7', 'instlevel8', 'instlevel9',\n",
    "                 'epared1', 'epared2', 'epared3', 'etecho1', 'etecho2', 'etecho3', 'eviv1', 'eviv2', 'eviv3', 'refrig', 'television', 'mobilephone',\n",
    "            'area1', 'area2', 'v18q', 'edjef']\n",
    "    \n",
    "for lugar in ['lugar1', 'lugar2', 'lugar3', 'lugar4', 'lugar5', 'lugar6']:\n",
    "    group_train = df_train[[lugar, 'idhogar'] + aggr_list].groupby([lugar, 'idhogar']).sum().reset_index()\n",
    "    group_train.columns = [lugar, 'idhogar'] + ['new4_{}_idhogar_{}'.format(lugar, col) for col in group_train][2:]\n",
    "\n",
    "    group_test = df_test[[lugar, 'idhogar'] + aggr_list].groupby([lugar, 'idhogar']).sum().reset_index()\n",
    "    group_test.columns = [lugar, 'idhogar'] + ['new4_{}_idhogar_{}'.format(lugar, col) for col in group_test][2:]\n",
    "\n",
    "    train_agg = pd.merge(train_agg, group_train, on=[lugar, 'idhogar'])\n",
    "    test = pd.merge(test, group_test, on=[lugar, 'idhogar'])\n",
    "    \n",
    "print('train shape:', train_agg.shape, 'test shape:', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d9b5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_nums = ['age', 'meaneduc', 'dependency', \n",
    "             'hogar_nin', 'hogar_adul', 'hogar_mayor', 'hogar_total',\n",
    "             'bedrooms', 'overcrowding']\n",
    "\n",
    "for function in tqdm(['mean','std','min','max','sum', 'count', max_min]):\n",
    "    for lugar in ['lugar1', 'lugar2', 'lugar3', 'lugar4', 'lugar5', 'lugar6']:\n",
    "        group_train = df_train[[lugar, 'idhogar'] + aggr_list].groupby([lugar, 'idhogar']).agg(function).reset_index()\n",
    "        group_train.columns = [lugar, 'idhogar'] + ['new5_{}_idhogar_{}_{}'.format(lugar, col, function) for col in group_train][2:]\n",
    "\n",
    "        group_test = df_test[[lugar, 'idhogar'] + aggr_list].groupby([lugar, 'idhogar']).agg(function).reset_index()\n",
    "        group_test.columns = [lugar, 'idhogar'] + ['new5_{}_idhogar_{}_{}'.format(lugar, col, function) for col in group_test][2:]\n",
    "\n",
    "        train_agg = pd.merge(train_agg, group_train, on=[lugar, 'idhogar'])\n",
    "        test = pd.merge(test, group_test, on=[lugar, 'idhogar'])\n",
    "        \n",
    "print('train shape:', train_agg.shape, 'test shape:', test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f27d7ac",
   "metadata": {},
   "source": [
    "* According to data descriptions,ONLY the heads of household are used in scoring. /\n",
    "* All household members are included in test + the sample submission, but only heads of households are scored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b1edaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_agg.query('parentesco1==1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccd0249",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['dependency'].replace(np.inf, 0, inplace=True)\n",
    "test['dependency'].replace(np.inf, 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87302aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = test[['Id']]\n",
    "\n",
    "#Remove useless feature to reduce dimension\n",
    "train.drop(columns=['idhogar','Id', 'agesq', 'hogar_adul', 'SQBescolari', 'SQBage', 'SQBhogar_total', 'SQBedjefe', 'SQBhogar_nin', 'SQBovercrowding', 'SQBdependency', 'SQBmeaned'], inplace=True)\n",
    "test.drop(columns=['idhogar','Id',  'agesq', 'hogar_adul', 'SQBescolari', 'SQBage', 'SQBhogar_total', 'SQBedjefe', 'SQBhogar_nin', 'SQBovercrowding', 'SQBdependency', 'SQBmeaned'], inplace=True)\n",
    "\n",
    "correlation = train.corr()\n",
    "correlation = correlation['Target'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd76063",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('final_data size', train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcad8976",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The most 20 positive feature: \\n{correlation.head(40)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1fa763",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The most 20 negative feature: \\n{correlation.tail(20)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a7034c",
   "metadata": {},
   "source": [
    "\n",
    "# 4. Feature selection using shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deaa6cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_cat_features = [col for col in train.columns if train[col].value_counts().shape[0] == 2]\n",
    "object_features = ['edjefe', 'edjefa']\n",
    "\n",
    "categorical_feats = binary_cat_features + object_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86aeda5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_macroF1_lgb(truth, predictions):  \n",
    "    # this follows the discussion in https://github.com/Microsoft/LightGBM/issues/1483\n",
    "    pred_labels = predictions.reshape(len(np.unique(truth)),-1).argmax(axis=0)\n",
    "    f1 = f1_score(truth, pred_labels, average='macro')\n",
    "    return ('macroF1', f1, True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9eb912",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train['Target']\n",
    "train.drop(columns=['Target'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986cf6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_execution_time(start):\n",
    "    end = time.time()\n",
    "    hours, rem = divmod(end-start, 3600)\n",
    "    minutes, seconds = divmod(rem, 60)\n",
    "    print('*'*20, \"Execution ended in {:0>2}h {:0>2}m {:05.2f}s\".format(int(hours),int(minutes),seconds), '*'*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8df640",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split, ShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffd2df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_good_features_using_shap_LGB(params, SEED):\n",
    "    clf = lgb.LGBMClassifier(objective='multiclass',\n",
    "                             random_state=1989,\n",
    "                             max_depth=params['max_depth'], \n",
    "                             learning_rate=params['learning_rate'],  \n",
    "                             silent=True, \n",
    "                             metric='multi_logloss',\n",
    "                             n_jobs=-1, n_estimators=10000, \n",
    "                             class_weight='balanced',\n",
    "                             colsample_bytree = params['colsample_bytree'], \n",
    "                             min_split_gain= params['min_split_gain'], \n",
    "                             bagging_freq = params['bagging_freq'],\n",
    "                             min_child_weight=params['min_child_weight'],\n",
    "                             num_leaves = params['num_leaves'], \n",
    "                             subsample = params['subsample'],\n",
    "                             reg_alpha= params['reg_alpha'],\n",
    "                             reg_lambda= params['reg_lambda'],\n",
    "                             num_class=len(np.unique(y)),\n",
    "                             bagging_seed=SEED,\n",
    "                             seed=SEED,\n",
    "                            )\n",
    "\n",
    "    kfold = 5\n",
    "    kf = StratifiedKFold(n_splits=kfold, shuffle=True)\n",
    "    feat_importance_df  = pd.DataFrame()\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(train, y)):\n",
    "        print('='*30, '{} of {} folds'.format(i+1, kfold), '='*30)\n",
    "        start = time.time()\n",
    "        X_train, X_val = train.iloc[train_index], train.iloc[test_index]\n",
    "        y_train, y_val = y.iloc[train_index], y.iloc[test_index]\n",
    "        clf.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_val, y_val)], eval_metric=evaluate_macroF1_lgb, categorical_feature=categorical_feats,\n",
    "                early_stopping_rounds=500, verbose=500)\n",
    "        shap_values = shap.TreeExplainer(clf.booster_).shap_values(X_train)\n",
    "        fold_importance_df  = pd.DataFrame()\n",
    "        fold_importance_df['feature'] = X_train.columns\n",
    "        fold_importance_df['shap_values'] = abs(np.array(shap_values)[:, :].mean(1).mean(0))\n",
    "        fold_importance_df['feat_imp'] = clf.feature_importances_\n",
    "        feat_importance_df = pd.concat([feat_importance_df, fold_importance_df])\n",
    "        print_execution_time(start)\n",
    "\n",
    "    feat_importance_df_shap = feat_importance_df.groupby('feature').mean().sort_values('shap_values', ascending=False).reset_index()\n",
    "#     feat_importance_df_shap['shap_cumsum'] = feat_importance_df_shap['shap_values'].cumsum() / feat_importance_df_shap['shap_values'].sum()\n",
    "#     good_features = feat_importance_df_shap.loc[feat_importance_df_shap['shap_cumsum'] < 0.999].feature\n",
    "    return feat_importance_df_shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c274ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_shap_df  = pd.DataFrame()\n",
    "NUM_ITERATIONS = 50\n",
    "for SEED in range(NUM_ITERATIONS):\n",
    "    print('#'*40, '{} of {} iterations'.format(SEED+1, NUM_ITERATIONS), '#' * 40)\n",
    "    params = {'max_depth': np.random.choice([5, 6, 7, 8, 10, 12, -1]),\n",
    "             'learning_rate': np.random.rand() * 0.02,\n",
    "              'colsample_bytree': np.random.rand() * (1 - 0.5) + 0.5,\n",
    "              'subsample': np.random.rand() * (1 - 0.5) + 0.5,\n",
    "              'min_split_gain': np.random.rand() * 0.2,\n",
    "              'num_leaves': np.random.choice([32, 48, 64]),\n",
    "              'reg_alpha': np.random.rand() * 2,\n",
    "              'reg_lambda': np.random.rand() *2,\n",
    "              'bagging_freq': np.random.randint(4) +1,\n",
    "              'min_child_weight': np.random.randint(100) + 20\n",
    "             }\n",
    "    temp_shap_df = extract_good_features_using_shap_LGB(params, SEED)\n",
    "    total_shap_df = pd.concat([total_shap_df, temp_shap_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c29c7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_sorted_df = total_shap_df.groupby('feature').mean().sort_values('shap_values', ascending=False).reset_index()\n",
    "feat_imp_sorted_df = total_shap_df.groupby('feature').mean().sort_values('feat_imp', ascending=False).reset_index()\n",
    "features_top_shap = shap_sorted_df['feature'][:500]\n",
    "features_top_feat_imp = feat_imp_sorted_df['feature'][:500]\n",
    "top_features = pd.Series(features_top_shap.tolist() + features_top_feat_imp.tolist())\n",
    "top_features = top_features.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b519efe1",
   "metadata": {},
   "source": [
    "# 4. Model development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced95462",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train = train[top_features].copy()\n",
    "new_test = test[top_features].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad0ced4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('new_train shape:', new_train.shape, 'new_test shape:', new_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8a8e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_categorical_feats = [col for col in top_features if col in categorical_feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979e1ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LGB_OOF(params, categorical_feats, N_FOLDs, SEED=1989):\n",
    "    clf = lgb.LGBMClassifier(objective='multiclass',\n",
    "                             random_state=1989,\n",
    "                             max_depth=params['max_depth'], \n",
    "                             learning_rate=params['learning_rate'],  \n",
    "                             silent=True, \n",
    "                             metric='multi_logloss',\n",
    "                             n_jobs=-1, n_estimators=10000, \n",
    "                             class_weight='balanced',\n",
    "                             colsample_bytree = params['colsample_bytree'], \n",
    "                             min_split_gain= params['min_split_gain'], \n",
    "                             bagging_freq = params['bagging_freq'],\n",
    "                             min_child_weight=params['min_child_weight'],\n",
    "                             num_leaves = params['num_leaves'], \n",
    "                             subsample = params['subsample'],\n",
    "                             reg_alpha= params['reg_alpha'],\n",
    "                             reg_lambda= params['reg_lambda'],\n",
    "                             num_class=len(np.unique(y)),\n",
    "                             bagging_seed=SEED,\n",
    "                             seed=SEED,\n",
    "                            )\n",
    "\n",
    "    kfold = 10\n",
    "    kf = StratifiedKFold(n_splits=kfold, shuffle=True)\n",
    "    feat_importance_df  = pd.DataFrame()\n",
    "    predicts_result = []\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(new_train, y)):\n",
    "        print('='*30, '{} of {} folds'.format(i+1, kfold), '='*30)\n",
    "        start = time.time()\n",
    "        X_train, X_val = new_train.iloc[train_index], new_train.iloc[test_index]\n",
    "        y_train, y_val = y.iloc[train_index], y.iloc[test_index]\n",
    "        clf.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_val, y_val)], eval_metric=evaluate_macroF1_lgb,categorical_feature=new_categorical_feats,\n",
    "                early_stopping_rounds=500, verbose=500)\n",
    "        shap_values = shap.TreeExplainer(clf.booster_).shap_values(X_train)\n",
    "        fold_importance_df  = pd.DataFrame()\n",
    "        fold_importance_df['feature'] = X_train.columns\n",
    "        fold_importance_df['shap_values'] = abs(np.array(shap_values)[:, :].mean(1).mean(0))\n",
    "        fold_importance_df['feat_imp'] = clf.feature_importances_\n",
    "        feat_importance_df = pd.concat([feat_importance_df, fold_importance_df])\n",
    "        predicts_result.append(clf.predict(new_test))\n",
    "        print_execution_time(start)\n",
    "    return predicts_result, feat_importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cef7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'max_depth': 6,\n",
    "         'learning_rate': 0.002,\n",
    "          'colsample_bytree': 0.8,\n",
    "          'subsample': 0.8,\n",
    "          'min_split_gain': 0.02,\n",
    "          'num_leaves': 48,\n",
    "          'reg_alpha': 0.04,\n",
    "          'reg_lambda': 0.073,\n",
    "          'bagging_freq': 2,\n",
    "          'min_child_weight': 40\n",
    "         }\n",
    "\n",
    "N_Folds = 20\n",
    "SEED = 1989\n",
    "predicts_result, feat_importance_df = LGB_OOF(params, new_categorical_feats, N_Folds, SEED=1989)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a89daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(20, 20))\n",
    "feat_importance_df_shap = feat_importance_df.groupby('feature').mean().sort_values('shap_values', ascending=False).reset_index()\n",
    "\n",
    "num_features = 50\n",
    "sns.barplot(x=feat_importance_df_shap.shap_values[:num_features], y=feat_importance_df_shap.feature[:num_features], ax=ax[0])\n",
    "ax[0].set_title('Feature importance based on shap values')\n",
    "\n",
    "feat_importance_df = feat_importance_df.groupby('feature').mean().sort_values('feat_imp', ascending=False).reset_index()\n",
    "\n",
    "num_features = 50\n",
    "sns.barplot(x=feat_importance_df.shap_values[:num_features], y=feat_importance_df.feature[:num_features], ax=ax[1])\n",
    "ax[1].set_title('Feaure importance based on feature importance from lgbm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d376a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['Target'] = np.array(predicts_result).mean(axis=0).round().astype(int)\n",
    "submission.to_csv('submission_with_new_feature_set.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d66644",
   "metadata": {},
   "source": [
    "### Randomized Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e717aa08",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_param = None\n",
    "lowest_cv = 1000\n",
    "total_iteration = 100\n",
    "for i in range(total_iteration):\n",
    "    print('-'*20, 'For {} of {} iterations'.format(i+1, total_iteration), '-'*20)\n",
    "    learning_rate = np.random.rand() * 0.02\n",
    "    n_folds = 3\n",
    "\n",
    "    num_class = len(np.unique(y))\n",
    "\n",
    "    params = {}\n",
    "    params['application'] = 'multiclass'\n",
    "    params['metric'] = 'multi_logloss'\n",
    "    params['num_class'] = num_class\n",
    "    params['class_weight'] = 'balanced'\n",
    "    params['num_leaves'] = np.random.randint(24, 48)\n",
    "    params['max_depth'] = np.random.randint(5, 8)\n",
    "    params['min_child_weight'] = np.random.randint(5, 50)\n",
    "    params['min_split_gain'] = np.random.rand() * 0.09\n",
    "    params['colsample_bytree'] = np.random.rand() * (0.9 - 0.1) + 0.1\n",
    "    params['subsample'] = np.random.rand() * (1 - 0.8) + 0.8\n",
    "    params['bagging_freq'] = np.random.randint(1, 5)\n",
    "    params['bagging_seed'] = np.random.randint(1, 5)\n",
    "    params['reg_alpha'] = np.random.rand() * 2\n",
    "    params['reg_lambda'] = np.random.rand() * 2\n",
    "    params['learning_rate'] = np.random.rand() * 0.02\n",
    "    params['seed']  =1989\n",
    "\n",
    "    d_train = lgb.Dataset(data=new_train, label=y.values-1, categorical_feature=new_categorical_feats, free_raw_data=False)\n",
    "    cv_results = lgb.cv(params=params, train_set=d_train, num_boost_round=10000, categorical_feature=new_categorical_feats,\n",
    "                        nfold=n_folds, stratified=True, shuffle=True, early_stopping_rounds=1, verbose_eval=1000)\n",
    "\n",
    "    min_cv_results = min(cv_results['multi_logloss-mean'])\n",
    "\n",
    "    if min_cv_results < lowest_cv:\n",
    "        lowest_cv = min_cv_results\n",
    "        optimized_param = params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed05e1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_Folds = 20\n",
    "SEED = 1989\n",
    "predicts_result, feat_importance_df = LGB_OOF(optimized_param, new_categorical_feats, N_Folds, SEED=1989)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34faca3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['Target'] = np.array(predicts_result).mean(axis=0).round().astype(int)\n",
    "submission.to_csv('submission_shap_randomized_search.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "45a1d27c74e2431cde41acf3ae6f92cbe46375ea1f895827e4ff662aab74db0b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
